@comment{}}

@comment{}}

@inproceedings{1704.00028,
 archiveprefix = {arXiv},
 author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 eprint = {1704.00028},
 link = {https://arxiv.org/abs/1704.00028},
 pages = {5767},
 publisher = {Curran Associates, Inc.},
 title = {Improved Training of {Wasserstein} {GANs}},
 type = {arXiv},
 url = {http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.pdf},
 volume = {30},
 year = {2017}
}

@article{Abel_2020,
 archiveprefix = {arXiv},
 author = {Abel, C. and others},
 doi = {10.1103/PhysRevLett.124.081803},
 eprint = {2001.11966},
 issn = {1079-7114},
 journal = {Phys. Rev. Lett.},
 month = {February},
 number = {8},
 pages = {081803},
 primaryclass = {hep-ex},
 publisher = {American Physical Society (APS)},
 title = {{Measurement of the Permanent Electric Dipole Moment of the Neutron}},
 url = {http://dx.doi.org/10.1103/PhysRevLett.124.081803},
 volume = {124},
 year = {2020}
}

@unpublished{acgd,
 archiveprefix = {arXiv},
 author = {Florian Schäfer and Hongkai Zheng and Anima Anandkumar},
 eprint = {1910.05852},
 link = {https://arxiv.org/abs/1910.05852},
 primaryclass = {cs.LG},
 title = {Implicit competitive regularization in {GANs}},
 type = {arXiv},
 year = {2019}
}

@article{adagrad,
 author = {John Duchi and Elad Hazan and Yoram Singer},
 journal = {Journal of Machine Learning Research},
 number = {61},
 pages = {2121--2159},
 title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
 url = {http://jmlr.org/papers/v12/duchi11a.html},
 volume = {12},
 year = {2011}
}

@misc{adamw,
 archiveprefix = {arXiv},
 author = {Ilya Loshchilov and Frank Hutter},
 eprint = {1711.05101},
 link = {https://arxiv.org/abs/1711.05101},
 primaryclass = {cs.LG},
 title = {Decoupled Weight Decay Regularization},
 type = {arXiv},
 year = {2019}
}

@article{Agostinelli:2002hh,
 author = {Agostinelli, S. and others},
 collaboration = {GEANT4},
 doi = {10.1016/S0168-9002(03)01368-8},
 journal = {Nucl. Instrum. Meth. A},
 pages = {250--303},
 reportnumber = {SLAC-PUB-9350, FERMILAB-PUB-03-339, CERN-IT-2002-003},
 slaccitation = {%%CITATION = NUIMA,A506,250;%%},
 title = {{GEANT4--a simulation toolkit}},
 volume = {506},
 year = {2003}
}

@article{ALICE:2008ngc,
 author = {Aamodt, K. and others},
 collaboration = {ALICE},
 doi = {10.1088/1748-0221/3/08/S08002},
 journal = {JINST},
 pages = {S08002},
 title = {{The ALICE experiment at the CERN LHC}},
 volume = {3},
 year = {2008}
}

@article{alphago2,
 abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1--4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence---the structure prediction component of the `protein folding problem'8---has been an important open research problem for more than 50 years9. Despite recent progress10--14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
 author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v Z}{\'\i}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
 bdsk-url-1 = {https://doi.org/10.1038/s41586-021-03819-2},
 date = {2021-08-01},
 doi = {10.1038/s41586-021-03819-2},
 id = {Jumper2021},
 journal = {Nature},
 number = {7873},
 pages = {583--589},
 title = {Highly accurate protein structure prediction with AlphaFold},
 url = {https://doi.org/10.1038/s41586-021-03819-2},
 volume = {596},
 year = {2021}
}

@article{Alves:2017she,
 archiveprefix = {arXiv},
 author = {Albrecht, Johannes and others},
 collaboration = {HEP Software Foundation},
 doi = {10.1007/s41781-018-0018-8},
 eprint = {1712.06982},
 journal = {Comput. Softw. Big Sci.},
 number = {1},
 pages = {7},
 primaryclass = {physics.comp-ph},
 reportnumber = {HSF-CWP-2017-01, HSF-CWP-2017-001, FERMILAB-PUB-17-607-CD},
 slaccitation = {%%CITATION = ARXIV:1712.06982;%%},
 title = {{A Roadmap for HEP Software and Computing R\&D for the 2020s}},
 volume = {3},
 year = {2019}
}

@article{Alwall:2014hca,
 abstract = {We discuss the theoretical bases that underpin the automation of the computations of tree-level and next-to-leading order cross sections, of their matching to parton shower simulations, and of the merging of matched samples that differ by light-parton mul-tiplicities. We present a computer program, MadGraph5 aMC@NLO, capable of handling all these computations-parton-level fixed order, shower-matched, merged-in a unified framework whose defining features are flexibility, high level of parallelisation, and human intervention limited to input physics quantities. We demonstrate the potential of the program by presenting selected phenomenological applications relevant to the LHC and to a 1-TeV e + e − collider. While next-to-leading order results are restricted to QCD corrections to SM processes in the first public version, we show that from the user viewpoint no changes have to be expected in the case of corrections due to any given renormalisable Lagrangian, and that the implementation of these are well under way.},
 archiveprefix = {arXiv},
 author = {Alwall, J. and Frederix, R. and Frixione, S. and Hirschi, V. and Maltoni, F. and Mattelaer, O. and Shao, H. -S. and Stelzer, T. and Torrielli, P. and Zaro, M.},
 doi = {10.1007/JHEP07(2014)079},
 eprint = {1405.0301},
 journal = {JHEP},
 keywords = {Monte Carlo Simulations,NLO Computations},
 pages = {079},
 primaryclass = {hep-ph},
 reportnumber = {CERN-PH-TH-2014-064, CP3-14-18, LPN14-066, MCNET-14-09, ZU-TH-14-14},
 title = {{The automated computation of tree-level and next-to-leading order differential cross sections, and their matching to parton shower simulations}},
 volume = {07},
 year = {2014}
}

@misc{amram2023calodiffusion,
 archiveprefix = {arXiv},
 author = {Oz Amram and Kevin Pedro},
 eprint = {2308.03876},
 link = {https://arxiv.org/abs/2308.03876},
 primaryclass = {physics.ins-det},
 title = {CaloDiffusion with GLaM for High Fidelity Calorimeter Simulation},
 type = {arXiv},
 year = {2023}
}

@misc{anomalygan,
 author = {Schlegl, Thomas and Seeböck, Philipp and Waldstein, Sebastian M. and Schmidt-Erfurth, Ursula and Langs, Georg},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1703.05921},
 keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery},
 url = {https://arxiv.org/abs/1703.05921},
 year = {2017}
}

@article{antikt,
 archiveprefix = {arXiv},
 author = {Cacciari, Matteo and Salam, Gavin P. and Soyez, Gregory},
 doi = {10.1088/1126-6708/2008/04/063},
 eprint = {0802.1189},
 journal = {JHEP},
 month = {04},
 number = {04},
 pages = {063},
 primaryclass = {hep-ph},
 publisher = {Springer Science and Business Media {LLC}},
 reportnumber = {LPTHE-07-03},
 slaccitation = {%%CITATION = ARXIV:0802.1189;%%},
 title = {{The anti-$k_t$ jet clustering algorithm}},
 url = {https://doi.org/10.1088%2F1126-6708%2F2008%2F04%2F063},
 volume = {04},
 year = {2008}
}

@unpublished{arjovsky2017wasserstein,
 archiveprefix = {arXiv},
 author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L\'{e}on},
 eprint = {1701.07875},
 link = {https://arxiv.org/abs/1701.07875},
 title = {Wasserstein {GAN}},
 type = {arXiv},
 year = {2017}
}

@article{atlas,
 author = {Aad, G. and others},
 collaboration = {ATLAS},
 doi = {10.1088/1748-0221/3/08/S08003},
 journal = {JINST},
 note = {Also published by CERN Geneva in 2010},
 pages = {S08003},
 title = {{The ATLAS Experiment at the CERN Large Hadron Collider}},
 url = {https://cds.cern.ch/record/1129811},
 volume = {3},
 year = {2008}
}

@misc{atlasopen,
 author = {{ATLAS Collaboration}},
 doi = {10.7483/OPENDATA.ATLAS.UXKX.TXBN},
 publisher = {CERN Open Data Portal},
 title = {Datasets used to train the Generative Adversarial Networks used in ATLFast3},
 url = {http://opendata.cern.ch/record/15012},
 year = {2021}
}

@article{attention,
 author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
 eprint = {1706.03762},
 eprinttype = {arXiv},
 journal = {CoRR},
 timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
 title = {Attention Is All You Need},
 url = {http://arxiv.org/abs/1706.03762},
 volume = {abs/1706.03762},
 year = {2017}
}

@misc{attention1,
 archiveprefix = {arXiv},
 author = {Minh-Thang Luong and Hieu Pham and Christopher D. Manning},
 eprint = {1508.04025},
 link = {https://arxiv.org/abs/1508.04025},
 primaryclass = {cs.CL},
 title = {Effective Approaches to Attention-based Neural Machine Translation},
 type = {arXiv},
 year = {2015}
}

@misc{attention2,
 archiveprefix = {arXiv},
 author = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
 eprint = {1409.0473},
 link = {https://arxiv.org/abs/1409.0473},
 primaryclass = {cs.CL},
 title = {Neural Machine Translation by Jointly Learning to Align and Translate},
 type = {arXiv},
 year = {2016}
}

@misc{attention3,
 archiveprefix = {arXiv},
 author = {Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhutdinov and Richard Zemel and Yoshua Bengio},
 eprint = {1502.03044},
 link = {https://arxiv.org/abs/1502.03044},
 primaryclass = {cs.LG},
 title = {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
 type = {arXiv},
 year = {2016}
}

@misc{attentionbirth,
 archiveprefix = {arXiv},
 author = {Alex Graves and Greg Wayne and Ivo Danihelka},
 eprint = {1410.5401},
 link = {https://arxiv.org/abs/1410.5401},
 primaryclass = {cs.NE},
 title = {Neural Turing Machines},
 type = {arXiv},
 year = {2014}
}

@article{Baldi:2014kfa,
 archiveprefix = {arXiv},
 author = {Baldi, Pierre and Sadowski, Peter and Whiteson, Daniel},
 doi = {10.1038/ncomms5308},
 eprint = {1402.4735},
 journal = {Nature Commun.},
 pages = {4308},
 primaryclass = {hep-ph},
 slaccitation = {%%CITATION = ARXIV:1402.4735;%%},
 title = {{Searching for Exotic Particles in High-Energy Physics with Deep Learning}},
 volume = {5},
 year = {2014}
}

@article{Ball:2012cx,
 archiveprefix = {arXiv},
 author = {Ball, Richard D. and others},
 doi = {10.1016/j.nuclphysb.2012.10.003},
 eprint = {1207.1303},
 journal = {Nucl. Phys. B},
 pages = {244--289},
 primaryclass = {hep-ph},
 reportnumber = {EDINBURGH-2012-08, IFUM-FT-997, FR-PHENO-2012-014, RWTH-TTK-12-25, CERN-PH-TH-2012-037, SFB-CPP-12-47},
 title = {{Parton distributions with LHC data}},
 volume = {867},
 year = {2013}
}

@article{Barlow:1993dm,
 author = {Barlow, Roger J. and Beeston, Christine},
 doi = {10.1016/0010-4655(93)90005-W},
 journal = {Comput. Phys. Commun.},
 pages = {219--228},
 reportnumber = {MAN-HEP-93-1},
 title = {{Fitting using finite Monte Carlo samples}},
 volume = {77},
 year = {1993}
}

@inproceedings{batchnorm,
 archiveprefix = {arXiv},
 author = {Ioffe, Sergey and Szegedy, Christian},
 booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
 editor = {Francis Bach and David Blei},
 eprint = {1502.03167},
 link = {https://arxiv.org/abs/1502.03167},
 location = {Lille, France},
 numpages = {9},
 pages = {448},
 publisher = {PMLR},
 title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
 type = {arXiv},
 url = {http://proceedings.mlr.press/v37/ioffe15.html},
 volume = {37},
 year = {2015}
}

@article{Belayneh:2019vyx,
 archiveprefix = {arXiv},
 author = {Belayneh, Dawit and others},
 doi = {10.1140/epjc/s10052-020-8251-9},
 eprint = {1912.06794},
 journal = {Eur. Phys. J. C},
 number = {7},
 pages = {688},
 primaryclass = {physics.ins-det},
 reportnumber = {FERMILAB-PUB-20-448-CMS},
 title = {{Calorimetry with deep learning: particle simulation and reconstruction for collider physics}},
 volume = {80},
 year = {2020}
}

@article{Belikov2014,
 author = {Belikov, Iouri},
 collaboration = {ALICE},
 doi = {10.1051/epjconf/20147000029},
 editor = {Bravina, Larissa and Foka, Yiota and Kabana, Sonia},
 journal = {EPJ Web Conf.},
 pages = {00029},
 publisher = {EDP Sciences},
 title = {{Event reconstruction and particle identification in the ALICE experiment at the LHC}},
 url = {https://doi.org/10.1051/epjconf/20147000029},
 volume = {70},
 year = {2014}
}

@inproceedings{Benekos2007,
 author = {Benekos, N. C.},
 booktitle = {{9th ICATPP Conference on Astroparticle, Particle, Space Physics, Detectors and Medical Physics Applications}},
 doi = {10.1142/9789812773678_0165},
 pages = {1027--1031},
 publisher = {World Scientific},
 title = {{Muon identification and reconstruction in the ATLAS detector at the LHC}},
 url = {https://doi.org/10.1142/9789812773678_0165},
 year = {2006}
}

@incollection{bengio2012practical,
 author = {Bengio, Yoshua},
 booktitle = {Neural networks: Tricks of the trade},
 pages = {437--478},
 publisher = {Springer},
 title = {Practical recommendations for gradient-based training of deep architectures},
 year = {2012}
}

@article{BERT,
 archiveprefix = {arXiv},
 author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1810.04805},
 eprint = {1810.04805},
 keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {10},
 primaryclass = {cs.CL},
 publisher = {arXiv},
 title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
 url = {https://arxiv.org/abs/1810.04805},
 year = {2018}
}

@inproceedings{betavae,
 author = {Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
 booktitle = {International Conference on Learning Representations},
 title = {beta-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
 url = {https://openreview.net/forum?id=Sy2fzU9gl},
 year = {2017}
}

@article{bibae,
 archiveprefix = {arXiv},
 author = {Buhmann, Erik and Diefenbacher, Sascha and Eren, Engin and Gaede, Frank and Kasieczka, Gregor and Korol, Anatolii and Kr\"uger, Katja},
 doi = {10.1007/s41781-021-00056-0},
 eprint = {2005.05334},
 journal = {Comput. Softw. Big Sci.},
 month = {05},
 number = {1},
 pages = {13},
 primaryclass = {physics.ins-det},
 publisher = {Springer Science and Business Media {LLC}},
 reportnumber = {DESY 20-075, DESY-20-075},
 title = {{Getting High: High Fidelity Simulation of High Granularity Calorimeters with High Speed}},
 url = {https://doi.org/10.1007%2Fs41781-021-00056-0},
 volume = {5},
 year = {2021}
}

@article{bibae2,
 archiveprefix = {arXiv},
 author = {Buhmann, Erik and Diefenbacher, Sascha and Eren, Engin and Gaede, Frank and Kasieczka, Gregor and Korol, Anatolii and Kr\"uger, Katja},
 doi = {10.1051/epjconf/202125103003},
 editor = {C. Biscarat and S. Campana and B. Hegner and S. Roiser and C.I. Rovelli and G.A. Stewart},
 eprint = {2102.12491},
 journal = {EPJ Web Conf.},
 pages = {03003},
 primaryclass = {physics.ins-det},
 publisher = {{EDP} Sciences},
 reportnumber = {DESY 21-029, DESY-21-029},
 title = {{Decoding Photons: Physics in the Latent Space of a BIB-AE Generative Network}},
 url = {https://doi.org/10.1051%2Fepjconf%2F202125103003},
 volume = {251},
 year = {2021}
}

@misc{birk2023flow,
 archiveprefix = {arXiv},
 author = {Joschka Birk and Erik Buhmann and Cedric Ewen and Gregor Kasieczka and David Shih},
 eprint = {2312.00123},
 link = {https://arxiv.org/abs/2312.00123},
 primaryclass = {hep-ph},
 title = {Flow Matching Beyond Kinematics: Generating Jets with Particle-ID and Trajectory Displacement Information},
 type = {arXiv},
 year = {2023}
}

@misc{bogatskiy2022pelican,
 archiveprefix = {arXiv},
 author = {Alexander Bogatskiy and Timothy Hoffman and David W. Miller and Jan T. Offermann},
 eprint = {2211.00454},
 link = {https://arxiv.org/abs/2211.00454},
 primaryclass = {hep-ph},
 title = {PELICAN: Permutation Equivariant and Lorentz Invariant or Covariant Aggregator Network for Particle Physics},
 type = {arXiv},
 year = {2022}
}

@unpublished{borji2021,
 archiveprefix = {arXiv},
 author = {Ali Borji},
 doi = {10.1016/j.cviu.2021.103329},
 eprint = {2103.09396},
 primaryclass = {cs.LG},
 title = {Pros and Cons of {GAN} Evaluation Measures: New Developments},
 year = {2021}
}

@inproceedings{Bortoli2021DiffusionSB,
 author = {Valentin De Bortoli and James Thornton and Jeremy Heng and A. Doucet},
 booktitle = {Neural Information Processing Systems},
 title = {Diffusion Schr{\"o}dinger Bridge with Applications to Score-Based Generative Modeling},
 url = {https://api.semanticscholar.org/CorpusID:235294278},
 year = {2021}
}

@article{boxcox,
 abstract = {In the analysis of data it is often assumed that observations y1, y2, ..., yn are independently normally distributed with constant variance and with expectations specified by a model linear in a set of parameters θ. In this paper we make the less restrictive assumption that such a normal, homoscedastic, linear model is appropriate after some suitable transformation has been applied to the y's. Inferences about the transformation and about the parameters of the linear model are made by computing the likelihood function and the relevant posterior distribution. The contributions of normality, homoscedasticity and additivity to the transformation are separated. The relation of the present methods to earlier procedures for finding transformations is discussed. The methods are illustrated with examples.},
 author = {G. E. P. Box and D. R. Cox},
 issn = {00359246},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {2},
 pages = {211--252},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {An Analysis of Transformations},
 url = {http://www.jstor.org/stable/2984418},
 urldate = {2023-06-16},
 volume = {26},
 year = {1964}
}

@book{Brehmer:2020cvb,
 archiveprefix = {arXiv},
 author = {Brehmer, Johann and Cranmer, Kyle},
 booktitle = {{Artificial Intelligence for High Energy Physics}},
 doi = {10.1142/12200},
 editor = {Calafiura, Paolo and Rousseau, David and Terao, Kazuhiro},
 eprint = {2010.06439},
 isbn = {978-981-12-3402-6, 978-981-12-3404-0},
 journal = {Int. J. Mod. Phys. A},
 month = {3},
 note = {Submitted to \emph{Int. J. Mod. Phys. A}},
 primaryclass = {hep-ph},
 publisher = {World Scientific},
 title = {{Artificial Intelligence for High Energy Physics}},
 year = {2022}
}

@misc{buhmann2023caloclouds,
 archiveprefix = {arXiv},
 author = {Erik Buhmann and Frank Gaede and Gregor Kasieczka and Anatolii Korol and William Korcari and Katja Krüger and Peter McKeown},
 eprint = {2309.05704},
 link = {https://arxiv.org/abs/2309.05704},
 primaryclass = {physics.ins-det},
 title = {CaloClouds II: Ultra-Fast Geometry-Independent Highly-Granular Calorimeter Simulation},
 type = {arXiv},
 year = {2023}
}

@misc{buhmann2023epicly,
 archiveprefix = {arXiv},
 author = {Erik Buhmann and Cedric Ewen and Darius A. Faroughy and Tobias Golling and Gregor Kasieczka and Matthew Leigh and Guillaume Quétant and John Andrew Raine and Debajyoti Sengupta and David Shih},
 eprint = {2310.00049},
 link = {https://arxiv.org/abs/2310.00049},
 primaryclass = {hep-ph},
 title = {EPiC-ly Fast Particle Cloud Generation with Flow-Matching and Diffusion},
 type = {arXiv},
 year = {2023}
}

@article{Butter:2019cae,
 archiveprefix = {arXiv},
 author = {Butter, Anja and Plehn, Tilman and Winterhalder, Ramon},
 doi = {10.21468/SciPostPhys.7.6.075},
 eprint = {1907.03764},
 journal = {SciPost Phys.},
 number = {6},
 pages = {075},
 primaryclass = {hep-ph},
 slaccitation = {%%CITATION = ARXIV:1907.03764;%%},
 title = {{How to GAN LHC Events}},
 volume = {7},
 year = {2019}
}

@article{Cacciapaglia:2013wha,
 archiveprefix = {arXiv},
 author = {Cacciapaglia, Giacomo and Deandrea, Aldo and Ellis, John and Marrouche, Jad and Panizzi, Luca},
 doi = {10.1103/PhysRevD.87.075006},
 eprint = {1302.4750},
 journal = {Phys. Rev. D},
 number = {7},
 pages = {075006},
 primaryclass = {hep-ph},
 reportnumber = {KCL-PH-TH-2013-05, LCTS-2013-02, CERN-PH-TH-2013-015, SHEP-13-06},
 title = {{LHC Missing-Transverse-Energy Constraints on Models with Universal Extra Dimensions}},
 volume = {87},
 year = {2013}
}

@misc{calochallenge2,
 author = {Faucci Giannelli, Michele and Kasieczka, Gregor and Krause, Claudius and Nachman, Ben and Salamani, Dalila and Shih, David and Zaborowska, Anna},
 doi = {10.5281/zenodo.6366271},
 month = {March},
 publisher = {Zenodo},
 title = {{Fast Calorimeter Simulation Challenge 2022 - Dataset 2}},
 url = {https://doi.org/10.5281/zenodo.6366271},
 year = {2022}
}

@misc{calochallengeflow1,
 archiveprefix = {arXiv},
 author = {Claudius Krause and Ian Pang and David Shih},
 eprint = {2210.14245},
 link = {https://arxiv.org/abs/2210.14245},
 primaryclass = {physics.ins-det},
 title = {CaloFlow for CaloChallenge Dataset 1},
 type = {arXiv},
 year = {2022}
}

@misc{calochallengeflow2,
 archiveprefix = {arXiv},
 author = {Matthew R. Buckley and Claudius Krause and Ian Pang and David Shih},
 eprint = {2305.11934},
 link = {https://doi.org/10.1103/PhysRevD.109.033006},
 primaryclass = {physics.ins-det},
 title = {Inductive CaloFlow},
 type = {DOI},
 year = {2023}
}

@misc{calochallengeflow3,
 archiveprefix = {arXiv},
 author = {Sascha Diefenbacher and Engin Eren and Frank Gaede and Gregor Kasieczka and Claudius Krause and Imahn Shekhzadeh and David Shih},
 eprint = {2302.11594},
 link = {https://doi.org/10.1088/1748-0221/18/10/P10017},
 primaryclass = {physics.ins-det},
 title = {L2LFlows: Generating High-Fidelity 3D Calorimeter Images},
 type = {DOI},
 year = {2023}
}

@misc{calochallengevae1,
 archiveprefix = {arXiv},
 author = {Jesse C. Cresswell and Brendan Leigh Ross and Gabriel Loaiza-Ganem and Humberto Reyes-Gonzalez and Marco Letizia and Anthony L. Caterini},
 eprint = {2211.15380},
 link = {https://arxiv.org/abs/2211.15380},
 primaryclass = {hep-ph},
 title = {CaloMan: Fast generation of calorimeter showers with density estimation on learned manifolds},
 type = {arXiv},
 year = {2022}
}

@article{caloflow,
 archiveprefix = {arXiv},
 author = {Krause, Claudius and Shih, David},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.1103/PhysRevD.107.113003},
 eprint = {2106.05285},
 journal = {Phys. Rev. D},
 keywords = {Instrumentation and Detectors (physics.ins-det), Machine Learning (cs.LG), High Energy Physics - Experiment (hep-ex), High Energy Physics - Phenomenology (hep-ph), Data Analysis, Statistics and Probability (physics.data-an), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
 number = {11},
 pages = {113003},
 primaryclass = {physics.ins-det},
 publisher = {arXiv},
 title = {{Fast and accurate simulations of calorimeter showers with normalizing flows}},
 url = {https://arxiv.org/abs/2106.05285},
 volume = {107},
 year = {2023}
}

@article{caloflow2,
 archiveprefix = {arXiv},
 author = {Krause, Claudius and Shih, David},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.1103/PhysRevD.107.113004},
 eprint = {2110.11377},
 journal = {Phys. Rev. D},
 keywords = {Instrumentation and Detectors (physics.ins-det), Machine Learning (cs.LG), High Energy Physics - Experiment (hep-ex), High Energy Physics - Phenomenology (hep-ph), Data Analysis, Statistics and Probability (physics.data-an), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
 number = {11},
 pages = {113004},
 primaryclass = {physics.ins-det},
 publisher = {arXiv},
 title = {{Accelerating accurate simulations of calorimeter showers with normalizing flows and probability density distillation}},
 url = {https://arxiv.org/abs/2110.11377},
 volume = {107},
 year = {2023}
}

@article{calogan,
 archiveprefix = {arXiv},
 author = {Paganini, Michela and de Oliveira, Luke and Nachman, Benjamin},
 doi = {10.1103/PhysRevD.97.014021},
 eprint = {1712.10321},
 journal = {Phys. Rev. D},
 month = {jan},
 number = {1},
 pages = {014021},
 primaryclass = {hep-ex},
 publisher = {American Physical Society ({APS})},
 slaccitation = {%%CITATION = ARXIV:1712.10321;%%},
 title = {{CaloGAN : Simulating 3D high energy particle showers in multilayer electromagnetic calorimeters with generative adversarial networks}},
 url = {https://doi.org/10.1103%2Fphysrevd.97.014021},
 volume = {97},
 year = {2018}
}

@article{carminati2020,
 author = {Carminati, Federico and Khattak, Gulrukh and Loncar, Vladimir and Nguyen, Thong Q. and Pierini, Maurizio and Brito Da Rocha, Ricardo and Samaras-Tsakiris, Konstantinos and Vallecorsa, Sofia and Vlimant, Jean-Roch},
 doi = {10.1088/1742-6596/1525/1/012064},
 journal = {J. Phys. Conf. Ser.},
 number = {1},
 pages = {012064},
 title = {{Generative Adversarial Networks for fast simulation}},
 volume = {1525},
 year = {2020}
}

@article{Carrazza:2019cnt,
 archiveprefix = {arXiv},
 author = {Carrazza, Stefano and Dreyer, Fr\'ed\'eric A.},
 doi = {10.1140/epjc/s10052-019-7501-1},
 eprint = {1909.01359},
 journal = {Eur. Phys. J. C},
 number = {11},
 pages = {979},
 primaryclass = {hep-ph},
 reportnumber = {OUTP-19-09P, TIF-UNIMI-2019-14},
 slaccitation = {%%CITATION = ARXIV:1909.01359;%%},
 title = {{Lund jet images from generative and cycle-consistent adversarial networks}},
 volume = {79},
 year = {2019}
}

@article{cdflipschitz,
 archiveprefix = {arXiv},
 author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1806.07366},
 eprint = {1806.07366},
 keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {6},
 primaryclass = {cs.LG},
 publisher = {arXiv},
 title = {{Neural Ordinary Differential Equations}},
 url = {https://arxiv.org/abs/1806.07366},
 year = {2018}
}

@article{chatgpt,
 author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
 journal = {OpenAI Blog},
 title = {Language Models are Unsupervised Multitask Learners},
 year = {2019}
}

@unpublished{chen2020data,
 archiveprefix = {arXiv},
 author = {Cheng Chen and Olmo Cerri and Thong Q. Nguyen and Jean-Roch Vlimant and Maurizio Pierini},
 eprint = {2010.01835},
 link = {https://arxiv.org/abs/2010.01835},
 primaryclass = {physics.comp-ph},
 title = {Data Augmentation at the {LHC} through Analysis-specific Fast Simulation with Deep Learning},
 type = {arXiv},
 year = {2020}
}

@techreport{cifar10,
 author = {Krizhevsky, Alex},
 institution = {Citeseer},
 title = {Learning multiple layers of features from tiny images},
 year = {2009}
}

@article{classifiermetric,
 archiveprefix = {arXiv},
 author = {Das, Ranit and Favaro, Luigi and Heimel, Theo and Krause, Claudius and Plehn, Tilman and Shih, David},
 eprint = {2305.16774},
 link = {https://doi.org/10.21468/SciPostPhys.16.1.031},
 month = {5},
 primaryclass = {hep-ph},
 title = {{How to Understand Limitations of Generative Networks}},
 type = {DOI},
 year = {2023}
}

@techreport{CMS-DP-2020-021,
 author = {{CMS Collaboration}},
 collaboration = {{CMS}},
 number = {CMS-DP-2020-021},
 title = {{ECAL} 2016 refined calibration and {Run2} summary plots},
 type = {CMS Detector Performance Summary},
 url = {https://cds.cern.ch/record/2717925},
 year = {2020}
}

@techreport{CMS-PAS-BTV-22-001,
 address = {Geneva},
 collaboration = {CMS},
 institution = {CERN},
 reportnumber = {CMS-PAS-BTV-22-001},
 title = {{Performance of heavy-flavour jet identification in
boosted topologies in proton-proton collisions at $\sqrt{s}
= 13~\mathrm{TeV}$}},
 url = {https://cds.cern.ch/record/2866276},
 year = {2023}
}

@article{CMS:2008xjf,
 author = {Chatrchyan, S. and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/3/08/S08004},
 journal = {JINST},
 pages = {S08004},
 title = {{The CMS Experiment at the CERN LHC}},
 volume = {3},
 year = {2008}
}

@article{CMS:2014fny,
 archiveprefix = {arXiv},
 author = {Chatrchyan, Serguei and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/9/06/P06009},
 eprint = {1403.2286},
 journal = {JINST},
 pages = {P06009},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-TRK-11-002, CERN-PH-EP-2014-028},
 title = {{Alignment of the CMS tracker with LHC and cosmic ray data}},
 volume = {9},
 year = {2014}
}

@article{CMS:2014pgm,
 archiveprefix = {arXiv},
 author = {Chatrchyan, Serguei and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/9/10/P10009},
 eprint = {1405.6569},
 journal = {JINST},
 number = {10},
 pages = {P10009},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-TRK-11-001, CERN-PH-EP-2014-070},
 title = {{Description and performance of track and primary-vertex reconstruction with the CMS tracker}},
 volume = {9},
 year = {2014}
}

@article{CMS:2015myp,
 archiveprefix = {arXiv},
 author = {Khachatryan, Vardan and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/10/08/P08010},
 eprint = {1502.02702},
 journal = {JINST},
 number = {08},
 pages = {P08010},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-EGM-14-001, CERN-PH-EP-2015-006},
 title = {{Performance of Photon Reconstruction and Identification with the CMS Detector in Proton-Proton Collisions at sqrt(s) = 8 TeV}},
 volume = {10},
 year = {2015}
}

@article{CMS:2015xaf,
 archiveprefix = {arXiv},
 author = {Khachatryan, Vardan and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/10/06/P06005},
 eprint = {1502.02701},
 journal = {JINST},
 number = {06},
 pages = {P06005},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-EGM-13-001, CERN-PH-EP-2015-004},
 slaccitation = {%%CITATION = ARXIV:1502.02701;%%},
 title = {{Performance of Electron Reconstruction and Selection with the CMS Detector in Proton-Proton Collisions at \ensuremath{\sqrt{}}s = 8  TeV}},
 volume = {10},
 year = {2015}
}

@article{CMS:2016lmd,
 archiveprefix = {arXiv},
 author = {Khachatryan, Vardan and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/12/02/P02014},
 eprint = {1607.03663},
 journal = {JINST},
 number = {02},
 pages = {P02014},
 primaryclass = {hep-ex},
 reportnumber = {CMS-JME-13-004, CERN-PH-EP-2015-305},
 slaccitation = {%%CITATION = ARXIV:1607.03663;%%},
 title = {{Jet energy scale and resolution in the CMS experiment in pp collisions at 8 TeV}},
 volume = {12},
 year = {2017}
}

@article{CMS:2016ngn,
 archiveprefix = {arXiv},
 author = {Khachatryan, Vardan and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/12/01/P01020},
 eprint = {1609.02366},
 journal = {JINST},
 number = {01},
 pages = {P01020},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-TRG-12-001, CERN-EP-2016-160},
 slaccitation = {%%CITATION = ARXIV:1609.02366;%%},
 title = {{The CMS trigger system}},
 volume = {12},
 year = {2017}
}

@article{CMS:2017yfk,
 archiveprefix = {arXiv},
 author = {Sirunyan, A. M. and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/12/10/P10003},
 eprint = {1706.04965},
 journal = {JINST},
 number = {10},
 pages = {P10003},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-PRF-14-001, CERN-EP-2017-110},
 slaccitation = {%%CITATION = ARXIV:1706.04965;%%},
 title = {{Particle-flow reconstruction and global event description with the CMS detector}},
 volume = {12},
 year = {2017}
}

@article{CMS:2018jrd,
 archiveprefix = {arXiv},
 author = {Sirunyan, A. M. and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/13/10/P10005},
 eprint = {1809.02816},
 journal = {JINST},
 number = {10},
 pages = {P10005},
 primaryclass = {hep-ex},
 reportnumber = {CMS-TAU-16-003, CERN-EP-2018-229},
 title = {{Performance of reconstruction and identification of $\tau$ leptons decaying to hadrons and $\nu_\tau$ in pp collisions at $\sqrt{s}=$ 13 TeV}},
 volume = {13},
 year = {2018}
}

@article{CMS:2018rym,
 archiveprefix = {arXiv},
 author = {Sirunyan, A. M. and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/13/06/P06015},
 eprint = {1804.04528},
 journal = {JINST},
 number = {06},
 pages = {P06015},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-MUO-16-001, CERN-EP-2018-058},
 title = {{Performance of the CMS muon detector and muon reconstruction with proton-proton collisions at $\sqrt{s}=$ 13 TeV}},
 volume = {13},
 year = {2018}
}

@article{CMS:2019ctu,
 archiveprefix = {arXiv},
 author = {Sirunyan, Albert M and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/14/07/P07004},
 eprint = {1903.06078},
 journal = {JINST},
 number = {07},
 pages = {P07004},
 primaryclass = {hep-ex},
 reportnumber = {CMS-JME-17-001, CERN-EP-2018-335},
 slaccitation = {%%CITATION = ARXIV:1903.06078;%%},
 title = {{Performance of missing transverse momentum reconstruction in proton-proton collisions at $\sqrt{s} =$ 13 TeV using the CMS detector}},
 volume = {14},
 year = {2019}
}

@article{CMS:2019uxx,
 archiveprefix = {arXiv},
 author = {Sirunyan, Albert M and others},
 collaboration = {CMS},
 doi = {10.1007/s41781-020-00041-z},
 eprint = {1912.06046},
 journal = {Comput. Softw. Big Sci.},
 number = {1},
 pages = {10},
 primaryclass = {physics.data-an},
 reportnumber = {CMS-HIG-18-027, CERN-EP-2019-261},
 title = {{A Deep Neural Network for Simultaneous Estimation of b Jet Energy and Resolution}},
 volume = {4},
 year = {2020}
}

@article{CMS:2020cmk,
 archiveprefix = {arXiv},
 author = {Sirunyan, Albert M and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/15/10/P10017},
 eprint = {2006.10165},
 journal = {JINST},
 number = {10},
 pages = {P10017},
 primaryclass = {hep-ex},
 reportnumber = {CMS-TRG-17-001, CERN-EP-2020-065},
 title = {{Performance of the CMS Level-1 trigger in proton-proton collisions at $\sqrt{s} =$ 13 TeV}},
 volume = {15},
 year = {2020}
}

@article{CMS:2020ebo,
 archiveprefix = {arXiv},
 author = {Sirunyan, Albert M and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/15/09/P09018},
 eprint = {2003.00503},
 journal = {JINST},
 number = {09},
 pages = {P09018},
 primaryclass = {hep-ex},
 reportnumber = {CMS-JME-18-001, CERN-EP-2020-017},
 title = {{Pileup mitigation at CMS in 13 TeV data}},
 volume = {15},
 year = {2020}
}

@article{CMS:2020uim,
 archiveprefix = {arXiv},
 author = {Sirunyan, Albert M and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/16/05/P05014},
 eprint = {2012.06888},
 journal = {JINST},
 number = {05},
 pages = {P05014},
 primaryclass = {hep-ex},
 reportnumber = {CMS-EGM-17-001, CERN-EP-2020-219},
 title = {{Electron and photon reconstruction and identification with the CMS experiment at the CERN LHC}},
 volume = {16},
 year = {2021}
}

@article{CMS:2021ime,
 archiveprefix = {arXiv},
 author = {Tumasyan, Armen and others},
 collaboration = {CMS},
 doi = {10.1016/j.nima.2022.166795},
 eprint = {2111.08757},
 journal = {Nucl. Instrum. Meth. A},
 pages = {166795},
 primaryclass = {physics.ins-det},
 reportnumber = {CMS-TRK-20-001, CERN-EP-2021-203},
 title = {{Strategies and performance of the CMS silicon tracker alignment during LHC Run~2}},
 volume = {1037},
 year = {2022}
}

@article{cmsfig,
 author = {Bauer, Julia and Muller, Thomas},
 month = {09},
 pages = {},
 title = {Prospects for the Observation of Electroweak Top Quark Production with the CMS Experiment},
 year = {2023}
}

@article{cnn,
 added-at = {2010-06-28T21:14:36.000+0200},
 author = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
 biburl = {https://www.bibsonomy.org/bibtex/29aa18bc67d862bdb83b6081e5506f050/mhwombat},
 booktitle = {Proceedings of the IEEE},
 citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665},
 file = {:neural_nets/lecun-98.pdf:PDF;:lecun-98.pdf:PDF},
 groups = {public},
 interhash = {7a82cccacd23cf06b25ff5325a6c86c7},
 intrahash = {9aa18bc67d862bdb83b6081e5506f050},
 journal = {Proceedings of the IEEE},
 keywords = {MSc character_recognition checked mnist network neural},
 number = {11},
 organization = {IEEE},
 pages = {2278--2324},
 timestamp = {2016-07-12T19:25:30.000+0200},
 title = {Gradient-based learning applied to document recognition},
 url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665},
 username = {mhwombat},
 volume = {86},
 year = {1998}
}

@article{Coleman:2017fiq,
 archiveprefix = {arXiv},
 author = {Coleman, Evan and Freytsis, Marat and Hinzmann, Andreas and Narain, Meenakshi and Thaler, Jesse and Tran, Nhan and Vernieri, Caterina},
 doi = {10.1088/1748-0221/13/01/T01003},
 eprint = {1709.08705},
 journal = {JINST},
 number = {01},
 pages = {T01003},
 primaryclass = {hep-ph},
 reportnumber = {FERMILAB-PUB-17-347-E, MIT-CTP-4935},
 slaccitation = {%%CITATION = ARXIV:1709.08705;%%},
 title = {{The importance of calorimetry for highly-boosted jet substructure}},
 volume = {13},
 year = {2018}
}

@article{Cowan:2010js,
 archiveprefix = {arXiv},
 author = {Cowan, Glen and Cranmer, Kyle and Gross, Eilam and Vitells, Ofer},
 doi = {10.1140/epjc/s10052-011-1554-0},
 eprint = {1007.1727},
 journal = {Eur. Phys. J. C},
 note = {[Erratum: Eur.Phys.J.C 73, 2501 (2013)]},
 pages = {1554},
 primaryclass = {physics.data-an},
 title = {{Asymptotic formulae for likelihood-based tests of new physics}},
 volume = {71},
 year = {2011}
}

@article{CowanPDGStat,
 author = {Zyla, P. A. and others},
 collaboration = {Particle Data Group},
 doi = {10.1093/ptep/ptaa104},
 journal = {PTEP},
 number = {8},
 pages = {083C01},
 title = {{Review of Particle Physics}},
 url = {https://pdg.lbl.gov/2021/reviews/rpp2020-rev-statistics.pdf},
 volume = {2020},
 year = {2020}
}

@article{Cranmer30055,
 archiveprefix = {arXiv},
 author = {Cranmer, Kyle and Brehmer, Johann and Louppe, Gilles},
 doi = {10.1073/pnas.1912789117},
 eprint = {1911.01429},
 issn = {0027-8424},
 journal = {Proc. Nat. Acad. Sci.},
 number = {48},
 pages = {30055--30062},
 primaryclass = {stat.ML},
 publisher = {National Academy of Sciences},
 title = {{The frontier of simulation-based inference}},
 volume = {117},
 year = {2020}
}

@misc{cyclegan,
 author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1703.10593},
 keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
 url = {https://arxiv.org/abs/1703.10593},
 year = {2017}
}

@misc{dallee,
 archiveprefix = {arXiv},
 author = {Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
 eprint = {2204.06125},
 link = {https://arxiv.org/abs/2204.06125},
 primaryclass = {cs.CV},
 title = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
 type = {arXiv},
 year = {2022}
}

@inproceedings{dao2022flashattention,
 author = {Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
 year = {2022}
}

@article{dao2023flashattention2,
 author = {Dao, Tri},
 title = {Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
 year = {2023}
}

@misc{datahunger,
 archiveprefix = {arXiv},
 author = {Ali Hassani and Steven Walton and Nikhil Shah and Abulikemu Abuduweili and Jiachen Li and Humphrey Shi},
 eprint = {2104.05704},
 link = {https://arxiv.org/abs/2104.05704},
 primaryclass = {cs.CV},
 title = {Escaping the Big Data Paradigm with Compact Transformers},
 type = {arXiv},
 year = {2022}
}

@misc{dataset1,
 author = {Giannelli,  Michele Faucci and Kasieczka,  Gregor and Krause,  Claudius and Nachman,  Ben and Salamani,  Dalila and Shih,  David and Zaborowska,  Anna},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.5281/ZENODO.8099322},
 keywords = {CaloChallenge,  Calorimeter,  Generative Model},
 publisher = {Zenodo},
 title = {Fast Calorimeter Simulation Challenge 2022 - Dataset 1},
 url = {https://zenodo.org/record/8099322},
 year = {2023}
}

@misc{dataset2,
 author = {Faucci Giannelli,  Michele and Kasieczka,  Gregor and Krause,  Claudius and Nachman,  Ben and Salamani,  Dalila and Shih,  David and Zaborowska,  Anna},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.5281/ZENODO.6366270},
 keywords = {CaloChallenge,  Calorimeter,  Generative Model},
 publisher = {Zenodo},
 title = {Fast Calorimeter Simulation Challenge 2022 - Dataset 2},
 url = {https://zenodo.org/record/6366270},
 year = {2022}
}

@misc{dataset3,
 author = {Faucci Giannelli,  Michele and Kasieczka,  Gregor and Krause,  Claudius and Nachman,  Ben and Salamani,  Dalila and Shih,  David and Zaborowska,  Anna},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.5281/ZENODO.6366324},
 keywords = {CaloChallenge,  Calorimeter,  Generative Model},
 publisher = {Zenodo},
 title = {Fast Calorimeter Simulation Challenge 2022 - Dataset 3},
 url = {https://zenodo.org/record/6366324},
 year = {2022}
}

@inproceedings{dcgan,
 archiveprefix = {arXiv},
 author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1511.06434},
 eprint = {1511.06434},
 keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {11},
 primaryclass = {cs.LG},
 publisher = {arXiv},
 title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
 url = {https://arxiv.org/abs/1511.06434},
 year = {2015}
}

@article{deepbenefits,
 author = {Telgarsky, Matus},
 month = {02},
 pages = {},
 title = {Benefits of depth in neural networks},
 year = {2016}
}

@article{deepcsv,
 archiveprefix = {arXiv},
 author = {Guest, Daniel and Collado, Julian and Baldi, Pierre and Hsu, Shih-Chieh and Urban, Gregor and Whiteson, Daniel},
 doi = {10.1103/PhysRevD.94.112002},
 eprint = {1607.08633},
 journal = {Phys. Rev. D},
 month = {12},
 number = {11},
 pages = {112002},
 primaryclass = {hep-ex},
 publisher = {American Physical Society ({APS})},
 title = {{Jet Flavor Classification in High-Energy Physics with Deep Neural Networks}},
 url = {https://doi.org/10.1103%2Fphysrevd.94.112002},
 volume = {94},
 year = {2016}
}

@misc{deepsets,
 archiveprefix = {arXiv},
 author = {Manzil Zaheer and Satwik Kottur and Siamak Ravanbakhsh and Barnabas Poczos and Ruslan Salakhutdinov and Alexander Smola},
 eprint = {1703.06114},
 link = {https://arxiv.org/abs/1703.06114},
 primaryclass = {cs.LG},
 title = {Deep Sets},
 type = {arXiv},
 year = {2018}
}

@misc{deepsetscorr,
 archiveprefix = {arXiv},
 author = {Edward Wagstaff and Fabian B. Fuchs and Martin Engelcke and Ingmar Posner and Michael Osborne},
 eprint = {1901.09006},
 link = {https://arxiv.org/abs/1901.09006},
 primaryclass = {cs.LG},
 title = {On the Limitations of Representing Functions on Sets},
 type = {arXiv},
 year = {2019}
}

@inproceedings{deepvswide,
 author = {Zagoruyko, Sergey and Komodakis, Nikos},
 doi = {10.5244/C.30.87},
 month = {01},
 pages = {87.1--87.12},
 title = {Wide Residual Networks},
 year = {2016}
}

@inproceedings{denoisingautencoder,
 author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
 booktitle = {Proceedings of the 25th international conference on Machine learning},
 organization = {ACM},
 pages = {1096--1103},
 title = {Extracting and Composing Robust Features with Denoising Autoencoders},
 year = {2008}
}

@article{deOliveira:2015xxd,
 archiveprefix = {arXiv},
 author = {de Oliveira, Luke and Kagan, Michael and Mackey, Lester and Nachman, Benjamin and Schwartzman, Ariel},
 doi = {10.1007/JHEP07(2016)069},
 eprint = {1511.05190},
 journal = {JHEP},
 pages = {069},
 primaryclass = {hep-ph},
 title = {{Jet-images \textemdash{} deep learning edition}},
 volume = {07},
 year = {2016}
}

@misc{diefenbacher2023refining,
 archiveprefix = {arXiv},
 author = {Sascha Diefenbacher and Vinicius Mikuni and Benjamin Nachman},
 eprint = {2308.12339},
 link = {https://arxiv.org/abs/2308.12339},
 primaryclass = {physics.ins-det},
 title = {Refining Fast Calorimeter Simulations with a Schr\"{o}dinger Bridge},
 type = {arXiv},
 year = {2023}
}

@misc{diffbeatsgan,
 archiveprefix = {arXiv},
 author = {Prafulla Dhariwal and Alex Nichol},
 eprint = {2105.05233},
 link = {https://arxiv.org/abs/2105.05233},
 primaryclass = {cs.LG},
 title = {Diffusion Models Beat GANs on Image Synthesis},
 type = {arXiv},
 year = {2021}
}

@misc{diffusionnoise,
 archiveprefix = {arXiv},
 author = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
 eprint = {2006.11239},
 link = {https://arxiv.org/abs/2006.11239},
 primaryclass = {cs.LG},
 title = {Denoising Diffusion Probabilistic Models},
 type = {arXiv},
 year = {2020}
}

@article{discoflow,
 archiveprefix = {arXiv},
 author = {Klein, Samuel and Golling, Tobias},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.48550/ARXIV.2211.02486},
 eprint = {2211.02486},
 keywords = {High Energy Physics - Phenomenology (hep-ph), Machine Learning (cs.LG), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {11},
 primaryclass = {hep-ph},
 publisher = {arXiv},
 title = {{Decorrelation with conditional normalizing flows}},
 url = {https://arxiv.org/abs/2211.02486},
 year = {2022}
}

@inproceedings{discretepointflow,
 address = {Cham},
 archiveprefix = {arXiv},
 author = {Roman Klokov and Edmond Boyer and Jakob Verbeek},
 booktitle = {2020 European Conference on Computer Vision (ECCV)},
 doi = {10.1007/978-3-030-58592-1_41},
 editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
 eprint = {2007.10170},
 pages = {694},
 primaryclass = {cs.CV},
 publisher = {Springer International Publishing},
 title = {Discrete Point Flow Networks for Efficient Point Cloud Generation},
 year = {2020}
}

@article{DiSipio:2019imz,
 archiveprefix = {arXiv},
 author = {Di Sipio, Riccardo and Faucci Giannelli, Michele and Ketabchi Haghighat, Sana and Palazzo, Serena},
 doi = {10.1007/JHEP08(2019)110},
 eprint = {1903.02433},
 journal = {JHEP},
 pages = {110},
 primaryclass = {hep-ex},
 slaccitation = {%%CITATION = ARXIV:1903.02433;%%},
 title = {{DijetGAN: A Generative-Adversarial Network Approach for the Simulation of QCD Dijet Events at the LHC}},
 volume = {08},
 year = {2019}
}

@misc{djouadi1999minimal,
 archiveprefix = {arXiv},
 author = {A. Djouadi and S. Rosier-Lees and M. Bezouh and M. A. Bizouard and C. Boehm and F. Borzumati and C. Briot and J. Carr and M. B. Causse and F. Charles and X. Chereau and P. Colas and L. Duflot and A. Dupperin and A. Ealet and H. El-Mamouni and N. Ghodbane and F. Gieres and B. Gonzalez-Pineiro and S. Gourmelen and G. Grenier and Ph. Gris and J. -F. Grivaz and C. Hebrard and B. Ille and J. -L. Kneur and N. Kostantinidis and J. Layssac and P. Lebrun and R. Ledu and M. -C. Lemaire and Ch. LeMouel and L. Lugnier and Y. Mambrini and J. P. Martin and G. Montarou and G. Moultaka and S. Muanza and E. Nuss and E. Perez and F. M. Renard and D. Reynaud and L. Serin and C. Thevenet and A. Trabelsi and F. Zach and D. Zerwas},
 eprint = {hep-ph/9901246},
 link = {https://arxiv.org/abs/hep-ph/9901246},
 primaryclass = {hep-ph},
 title = {The Minimal Supersymmetric Standard Model: Group Summary Report},
 type = {arXiv},
 year = {1999}
}

@book{dopri5,
 author = {Hairer, Ernst and Norsett, Syvert and Wanner, Gerhard},
 doi = {10.1007/978-3-540-78862-1},
 isbn = {978-3-540-56670-0},
 month = {01},
 pages = {},
 title = {Solving Ordinary Differential Equations I: Nonstiff Problems},
 volume = {8},
 year = {1993}
}

@article{dropout,
 author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
 journal = {Journal of Machine Learning Research},
 month = {06},
 pages = {1929--1958},
 title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
 volume = {15},
 year = {2014}
}

@article{dynamicgraphcnn,
 archiveprefix = {arXiv},
 author = {Yue Wang and Yongbin Sun and Ziwei Liu and Sanjay E. Sarma and Michael M. Bronstein and Justin M. Solomon},
 doi = {10.1145/3326362},
 eprint = {1801.07829},
 journal = {ACM Trans. Graph.},
 publisher = {Association for Computing Machinery},
 title = {Dynamic Graph {CNN} for Learning on Point Clouds},
 volume = {38},
 year = {2019}
}

@article{ecal_energy_resolution,
 author = {Adzic, P. and others},
 doi = {10.1088/1748-0221/2/04/P04004},
 journal = {JINST},
 pages = {P04004},
 reportnumber = {CERN-CMS-NOTE-2006-148},
 title = {{Energy resolution of the barrel of the CMS electromagnetic calorimeter}},
 volume = {2},
 year = {2007}
}

@article{ecalfig,
 author = {Marzocchi, Badder},
 collaboration = {CMS},
 doi = {10.1088/1742-6596/1162/1/012007},
 journal = {J. Phys. Conf. Ser.},
 month = {01},
 number = {1},
 pages = {012007},
 title = {{Simulation of the CMS electromagnetic calorimeter response at the energy and intensity frontier}},
 volume = {1162},
 year = {2019}
}

@misc{EFL,
 author = {Komiske, Patrick T. and others},
 note = {\url{https://energyflow.network}},
 title = {EnergyFlow library}
}

@book{Ellis:318585,
 address = {Cambridge},
 author = {Ellis, R. Keith and Stirling, W. James and Webber, B. R.},
 collection = {Cambridge Monographs on Particle Physics, Nuclear Physics and Cosmology},
 doi = {10.1017/CBO9780511628788},
 isbn = {978-0-511-82328-2, 978-0-521-54589-1},
 month = {2},
 note = {Photography by S. Vascotto},
 place = {Cambridge},
 publisher = {Cambridge University Press},
 series = {Cambridge monographs on particle physics, nuclear physics, and cosmology},
 title = {{QCD and collider physics}},
 url = {https://cds.cern.ch/record/318585},
 volume = {8},
 year = {2011}
}

@misc{ema,
 archiveprefix = {arXiv},
 author = {Yasin Yazıcı and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
 eprint = {1806.04498},
 link = {https://arxiv.org/abs/1806.04498},
 primaryclass = {stat.ML},
 title = {The Unusual Effectiveness of Averaging in GAN Training},
 type = {arXiv},
 year = {2019}
}

@article{emd,
 archiveprefix = {arXiv},
 author = {Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse},
 doi = {10.1103/PhysRevLett.123.041801},
 eprint = {1902.02346},
 journal = {Phys. Rev. Lett.},
 number = {4},
 pages = {041801},
 primaryclass = {hep-ph},
 reportnumber = {MIT-CTP 5102},
 title = {{Metric Space of Collider Events}},
 volume = {123},
 year = {2019}
}

@misc{epic,
 archiveprefix = {arXiv},
 author = {Erik Buhmann and Gregor Kasieczka and Jesse Thaler},
 eprint = {2301.08128},
 link = {https://doi.org/10.21468/SciPostPhys.15.4.130},
 primaryclass = {hep-ph},
 title = {EPiC-GAN: Equivariant Point Cloud Generation for Particle Jets},
 type = {DOI},
 year = {2023}
}

@misc{equivariance,
 archiveprefix = {arXiv},
 author = {Michael M. Bronstein and Joan Bruna and Taco Cohen and Petar Veličković},
 eprint = {2104.13478},
 link = {https://arxiv.org/abs/2104.13478},
 primaryclass = {cs.LG},
 title = {Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges},
 type = {arXiv},
 year = {2021}
}

@article{erdmann2019,
 archiveprefix = {arXiv},
 author = {Erdmann, Martin and Glombitza, Jonas and Quast, Thorben},
 doi = {10.1007/s41781-018-0019-7},
 eprint = {1807.01954},
 journal = {Comput. Softw. Big Sci.},
 number = {1},
 pages = {4},
 primaryclass = {physics.ins-det},
 slaccitation = {%%CITATION = ARXIV:1807.01954;%%},
 title = {{Precise simulation of electromagnetic calorimeter showers using a Wasserstein Generative Adversarial Network}},
 volume = {3},
 year = {2019}
}

@book{erdmann2021deep,
 author = {Erdmann, M. and Glombitza, J. and Kasieczka, G. and Klemradt, U.},
 isbn = {9789811237478},
 lccn = {2021024473},
 publisher = {World Scientific Publishing Company},
 title = {Deep Learning For Physics Research},
 url = {https://books.google.ch/books?id=8dM3EAAAQBAJ},
 year = {2021}
}

@article{Erdmann:2018kuh,
 archiveprefix = {arXiv},
 author = {Erdmann, Martin and Geiger, Lukas and Glombitza, Jonas and Schmidt, David},
 doi = {10.1007/s41781-018-0008-x},
 eprint = {1802.03325},
 journal = {Comput. Softw. Big Sci.},
 number = {1},
 pages = {4},
 primaryclass = {astro-ph.IM},
 slaccitation = {%%CITATION = ARXIV:1802.03325;%%},
 title = {{Generating and refining particle detector simulations using the Wasserstein distance in adversarial networks}},
 volume = {2},
 year = {2018}
}

@inbook{eulersmethod,
 abstract = {During the course of this book we will describe three families of methods for numerically solving IVPs: the Taylor series (TS) method, linear multistep methods (LMMs) and Runge--Kutta (RK) methods.},
 address = {London},
 author = {Griffiths, David F. and Higham, Desmond J.},
 bdsk-url-1 = {https://doi.org/10.1007/978-0-85729-148-6_2},
 booktitle = {Numerical Methods for Ordinary Differential Equations: Initial Value Problems},
 doi = {10.1007/978-0-85729-148-6_2},
 isbn = {978-0-85729-148-6},
 pages = {19--31},
 publisher = {Springer London},
 title = {Euler's Method},
 url = {https://doi.org/10.1007/978-0-85729-148-6_2},
 year = {2010}
}

@misc{f-gan,
 archiveprefix = {arXiv},
 author = {Sebastian Nowozin and Botond Cseke and Ryota Tomioka},
 eprint = {1606.00709},
 link = {https://arxiv.org/abs/1606.00709},
 primaryclass = {stat.ML},
 title = {f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization},
 type = {arXiv},
 year = {2016}
}

@techreport{fastcalogan,
 collaboration = {ATLAS},
 number = {ATL-SOFT-PUB-2020-006},
 reportnumber = {ATL-SOFT-PUB-2020-006},
 title = {Fast simulation of the {ATLAS} calorimeter system with Generative Adversarial Networks},
 type = {{ATLAS Software Public Note}},
 url = {https://cds.cern.ch/record/2746032},
 year = {2020}
}

@article{fastjet:1,
 archiveprefix = {arXiv},
 author = {Cacciari, Matteo and Salam, Gavin P. and Soyez, Gregory},
 doi = {10.1140/epjc/s10052-012-1896-2},
 eprint = {1111.6097},
 journal = {Eur. Phys. J. C},
 pages = {1896},
 primaryclass = {hep-ph},
 reportnumber = {CERN-PH-TH-2011-297},
 slaccitation = {%%CITATION = ARXIV:1111.6097;%%},
 title = {{FastJet User Manual}},
 volume = {72},
 year = {2012}
}

@article{fastjet:2,
 archiveprefix = {arXiv},
 author = {Cacciari, Matteo and Salam, Gavin P.},
 doi = {10.1016/j.physletb.2006.08.037},
 eprint = {hep-ph/0512210},
 journal = {Phys. Lett. B},
 pages = {57--61},
 primaryclass = {hep-ph},
 reportnumber = {LPTHE-05-32},
 slaccitation = {%%CITATION = PHLTA,B641,57;%%},
 title = {{Dispelling the $N^{3}$ myth for the $k_t$ jet-finder}},
 volume = {641},
 year = {2006}
}

@article{fastsim,
 archiveprefix = {arXiv},
 author = {Sekmen, Sezen},
 collaboration = {CMS},
 doi = {10.22323/1.282.0181},
 eprint = {1701.03850},
 journal = {PoS},
 pages = {181},
 primaryclass = {physics.ins-det},
 title = {{Recent Developments in CMS Fast Simulation}},
 volume = {ICHEP2016},
 year = {2016}
}

@misc{fdiv,
 archiveprefix = {arXiv},
 author = {Sebastian Nowozin and Botond Cseke and Ryota Tomioka},
 eprint = {1606.00709},
 link = {https://arxiv.org/abs/1606.00709},
 primaryclass = {stat.ML},
 title = {f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization},
 type = {arXiv},
 year = {2016}
}

@article{ffjord,
 archiveprefix = {arXiv},
 author = {Grathwohl, Will and Chen, Ricky T. Q. and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1810.01367},
 eprint = {1810.01367},
 keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {10},
 primaryclass = {cs.LG},
 publisher = {arXiv},
 title = {{FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models}},
 url = {https://arxiv.org/abs/1810.01367},
 year = {2018}
}

@misc{FGDINF,
 archiveprefix = {arXiv},
 author = {Min Jin Chong and David Forsyth},
 eprint = {1911.07023},
 link = {https://arxiv.org/abs/1911.07023},
 primaryclass = {cs.CV},
 title = {Effectively Unbiased FID and Inception Score and where to find them},
 type = {arXiv},
 year = {2020}
}

@article{flowstart,
 abstract = {A unified variational methodology is developed for classification and clustering problems and is tested in the classification of tumors from gene expression data. It is based on fluid-like flows in feature space that cluster a set of observations by transforming them into likely samples from p isotropic Gaussians, where p is the number of classes sought. The methodology blurs the distinction between training and testing populations through the soft assignment of both to classes. The observations act as Lagrangian markers for the flows, comparatively active or passive depending on the current strength of the assignment to the corresponding class.},
 author = {Agnelli, J. P. and Cadeiras, M. and Tabak, E. G. and Turner, C. V. and Vanden-Eijnden, E.},
 bdsk-url-1 = {https://doi.org/10.1137/100783522},
 doi = {10.1137/100783522},
 eprint = {https://doi.org/10.1137/100783522},
 journal = {Multiscale Modeling \& Simulation},
 number = {5},
 pages = {1784--1802},
 title = {Clustering and Classification through Normalizing Flows in Feature Space},
 url = {https://doi.org/10.1137/100783522},
 volume = {8},
 year = {2010}
}

@article{flowstart2,
 author = {Tabak, Esteban and Vanden-Eijnden, Eric},
 doi = {10.4310/CMS.2010.v8.n1.a11},
 journal = {Communications in Mathematical Sciences - COMMUN MATH SCI},
 month = {03},
 pages = {},
 title = {Density estimation by dual ascent of the log-likelihood},
 volume = {8},
 year = {2010}
}

@misc{flowuniversality1,
 author = {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1804.00779},
 keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Neural Autoregressive Flows},
 url = {https://arxiv.org/abs/1804.00779},
 year = {2018}
}

@inproceedings{flowuniversality2,
 abstract = {Triangular map is a recent construct in probability theory that allows one to transform any source probability density function to any target density function. Based on triangular maps, we propose a general framework for high-dimensional density estimation, by specifying one-dimensional transformations (equivalently conditional densities) and appropriate conditioner networks. This framework (a) reveals the commonalities and differences of existing autoregressive and flow based methods, (b) allows a unified understanding of the limitations and representation power of these recent approaches and, (c) motivates us to uncover a new Sum-of-Squares (SOS) flow that is interpretable, universal, and easy to train. We perform several synthetic experiments on various density geometries to demonstrate the benefits (and short-comings) of such transformations. SOS flows achieve competitive results in simulations and several real-world datasets.},
 author = {Jaini, Priyank and Selby, Kira A. and Yu, Yaoliang},
 booktitle = {Proceedings of the 36th International Conference on Machine Learning},
 editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
 month = {06},
 pages = {3009--3018},
 pdf = {http://proceedings.mlr.press/v97/jaini19a/jaini19a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Sum-of-Squares Polynomial Flow},
 url = {https://proceedings.mlr.press/v97/jaini19a.html},
 volume = {97},
 year = {2019}
}

@misc{flowuniversality3,
 author = {Teshima, Takeshi and Ishikawa, Isao and Tojo, Koichi and Oono, Kenta and Ikeda, Masahiro and Sugiyama, Masashi},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.2006.11469},
 keywords = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Classical Analysis and ODEs (math.CA), Differential Geometry (math.DG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
 publisher = {arXiv},
 title = {Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators},
 url = {https://arxiv.org/abs/2006.11469},
 year = {2020}
}

@article{Gallo2018,
 author = {Gallo, Valentina},
 collaboration = {ATLAS},
 doi = {10.22323/1.168.0001},
 journal = {PoS},
 pages = {001},
 publisher = {Sissa Medialab},
 title = {{Reconstruction and identification of electrons and photons with the ATLAS detector at the LHC}},
 url = {https://doi.org/10.22323/1.168.0001},
 volume = {IHEP-LHC-2011},
 year = {2011}
}

@article{GAN,
 archiveprefix = {arXiv},
 author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1406.2661},
 eprint = {1406.2661},
 keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {6},
 primaryclass = {stat.ML},
 publisher = {arXiv},
 title = {{Generative Adversarial Networks}},
 url = {https://arxiv.org/abs/1406.2661},
 year = {2014}
}

@article{ganbad,
 abstract = {Recently, Generative Adversarial Networks (GANs) trained on samples of traditionally simulated collider events have been proposed as a way of generating larger simulated datasets at a reduced computational cost. In this paper we point out that data generated by a GAN cannot statistically be better than the data it was trained on, and critically examine the applicability of GANs in various situations , including a) for replacing the entire Monte Carlo pipeline or parts of it, and b) to produce datasets for usage in highly sensitive analyses or sub-optimal ones. We present our arguments using information theoretic demonstrations, a toy example, as well as in the form of a theorem, and identify some potential valid uses of GANs in collider simulations.},
 archiveprefix = {arXiv},
 author = {Matchev, Konstantin T. and Roman, Alexander and Shyamsundar, Prasanth},
 doi = {10.21468/SciPostPhys.12.3.104},
 eprint = {2002.06307},
 journal = {SciPost Phys.},
 number = {3},
 pages = {104},
 primaryclass = {hep-ph},
 reportnumber = {FERMILAB-PUB-21-663-QIS},
 title = {{Uncertainties associated with GAN-generated datasets in high energy physics}},
 volume = {12},
 year = {2022}
}

@misc{ganbirth,
 archiveprefix = {arXiv},
 author = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
 eprint = {1406.2661},
 link = {https://arxiv.org/abs/1406.2661},
 primaryclass = {stat.ML},
 title = {Generative Adversarial Networks},
 type = {arXiv},
 year = {2014}
}

@misc{ganblurry,
 author = {Goodfellow, Ian J.},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1412.6515},
 keywords = {Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {On distinguishability criteria for estimating generative models},
 url = {https://arxiv.org/abs/1412.6515},
 year = {2014}
}

@article{ganfig,
 author = {Wang, Jian and Lv, Jiancheng and Yang, Xue and Tang, Chenwei and Peng, Xi},
 doi = {10.1007/s00500-020-05073-6},
 journal = {Soft Computing},
 month = {12},
 pages = {},
 title = {Multimodal image-to-image translation between domains with high internal variability},
 volume = {24},
 year = {2020}
}

@misc{ganlosses,
 author = {Lucic, Mario and Kurach, Karol and Michalski, Marcin and Gelly, Sylvain and Bousquet, Olivier},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1711.10337},
 keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Are GANs Created Equal? A Large-Scale Study},
 url = {https://arxiv.org/abs/1711.10337},
 year = {2017}
}

@misc{gantricks,
 archiveprefix = {arXiv},
 author = {Tim Salimans and Ian Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen},
 eprint = {1606.03498},
 link = {https://arxiv.org/abs/1606.03498},
 primaryclass = {cs.LG},
 title = {Improved Techniques for Training GANs},
 type = {arXiv},
 year = {2016}
}

@article{gcnn,
 author = {Cohen, Taco and Welling, Max},
 journal = {arXiv preprint arXiv:1602.07576},
 title = {Group equivariant convolutional networks},
 year = {2016}
}

@article{Geant4,
 author = {Agostinelli, S. and others},
 collaboration = {GEANT4},
 doi = {10.1016/S0168-9002(03)01368-8},
 issn = {0168-9002},
 journal = {Nucl. Instrum. Meth. A},
 keywords = {Simulation, Particle interactions, Geometrical modelling, Software engineering, Object-oriented technology, Distributed software development},
 number = {3},
 pages = {250--303},
 reportnumber = {SLAC-PUB-9350, FERMILAB-PUB-03-339, CERN-IT-2002-003},
 title = {{GEANT4--a simulation toolkit}},
 url = {https://www.sciencedirect.com/science/article/pii/S0168900203013688},
 volume = {506},
 year = {2003}
}

@misc{GELU,
 archiveprefix = {arXiv},
 author = {Dan Hendrycks and Kevin Gimpel},
 eprint = {1606.08415},
 link = {https://arxiv.org/abs/1606.08415},
 primaryclass = {cs.LG},
 title = {Gaussian Error Linear Units (GELUs)},
 type = {arXiv},
 year = {2020}
}

@inproceedings{glorot2010understanding,
 author = {Glorot, Xavier and Bengio, Yoshua},
 booktitle = {Proceedings of the thirteenth international conference on artificial intelligence and statistics},
 pages = {249--256},
 title = {Understanding the difficulty of training deep feedforward neural networks},
 year = {2010}
}

@article{glow,
 archiveprefix = {arXiv},
 author = {Kingma, Diederik P. and Dhariwal, Prafulla},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1807.03039},
 eprint = {1807.03039},
 keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {7},
 primaryclass = {stat.ML},
 publisher = {arXiv},
 title = {{Glow: Generative Flow with Invertible 1x1 Convolutions}},
 url = {https://arxiv.org/abs/1807.03039},
 year = {2018}
}

@misc{glu,
 archiveprefix = {arXiv},
 author = {Yann N. Dauphin and Angela Fan and Michael Auli and David Grangier},
 eprint = {1612.08083},
 link = {https://arxiv.org/abs/1612.08083},
 primaryclass = {cs.CL},
 title = {Language Modeling with Gated Convolutional Networks},
 type = {arXiv},
 year = {2017}
}

@article{gluon,
 archiveprefix = {arXiv},
 author = {Ellis, John},
 doi = {10.1142/S0217751X14300725},
 editor = {Fritzsch, Harald and Gell-Mann, Murray},
 eprint = {1409.4232},
 issn = {1793-656X},
 journal = {Int. J. Mod. Phys. A},
 month = {December},
 number = {31},
 pages = {1430072},
 primaryclass = {hep-ph},
 publisher = {World Scientific Pub Co Pte Lt},
 reportnumber = {KCL-PH-TH-2014-36, LCTS-2014-35, CERN-PH-TH-2014-178},
 title = {{The Discovery of the Gluon}},
 url = {http://dx.doi.org/10.1142/S0217751X14300725},
 volume = {29},
 year = {2014}
}

@article{gnn,
 author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
 journal = {IEEE Transactions on Neural Networks},
 number = {1},
 pages = {61--80},
 title = {The graph neural network model},
 volume = {20},
 year = {2009}
}

@article{GNNPP,
 archiveprefix = {arXiv},
 author = {Shlomi, Jonathan and Battaglia, Peter and Vlimant, Jean-Roch},
 doi = {10.1088/2632-2153/abbf9a},
 eprint = {2007.13681},
 journal = {Mach. Learn.: Sci. Technol.},
 month = {7},
 pages = {021001},
 primaryclass = {hep-ex},
 title = {{Graph Neural Networks in Particle Physics}},
 volume = {2},
 year = {2020}
}

@article{Goldstone:1962es,
 author = {Goldstone, Jeffrey and Salam, Abdus and Weinberg, Steven},
 doi = {10.1103/PhysRev.127.965},
 journal = {Phys. Rev.},
 pages = {965--970},
 title = {{Broken Symmetries}},
 volume = {127},
 year = {1962}
}

@book{Goodfellow-et-al-2016,
 author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
 note = {\url{http://www.deeplearningbook.org}},
 publisher = {MIT Press},
 title = {Deep Learning},
 year = {2016}
}

@inproceedings{Goodfellow:2014upx,
 archiveprefix = {arXiv},
 author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 doi = {10.1145/3422622},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
 eprint = {1406.2661},
 pages = {2672},
 primaryclass = {stat.ML},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Nets},
 url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
 volume = {27},
 year = {2014}
}

@misc{googleattention,
 author = {Rabe, Markus N. and Staats, Charles},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.2112.05682},
 eprint = {2112.05682},
 keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Self-attention Does Not Need $O(n^2)$ Memory},
 url = {https://arxiv.org/abs/2112.05682},
 year = {2021}
}

@inproceedings{graphcnngan,
 author = {Valsesia, Diego and Fracastoro, Giulia and Magli, Enrico},
 booktitle = {International Conference on Learning Representations (ICLR) 2019},
 title = {Learning Localized Generative Models for {3D} Point Clouds via Graph Convolution},
 url = {https://openreview.net/forum?id=SJeXSo09FQ},
 year = {2019}
}

@article{gregorfits,
 archiveprefix = {arXiv},
 author = {Butter, Anja and Diefenbacher, Sascha and Kasieczka, Gregor and Nachman, Benjamin and Plehn, Tilman},
 doi = {10.21468/SciPostPhys.10.6.139},
 eprint = {2008.06545},
 journal = {SciPost Phys.},
 month = {6},
 number = {6},
 pages = {139},
 primaryclass = {hep-ph},
 publisher = {Stichting {SciPost}},
 title = {{GANplifying event samples}},
 url = {https://doi.org/10.21468%2Fscipostphys.10.6.139},
 volume = {10},
 year = {2021}
}

@inproceedings{gschnet,
 archiveprefix = {arXiv},
 author = {Gebauer, Niklas and Gastegger, Michael and Sch{\"{u}}tt, Kristof},
 booktitle = {Advances in Neural Information Processing Systems 32},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 eprint = {1906.00957},
 link = {https://arxiv.org/abs/1906.00957},
 pages = {7566},
 primaryclass = {stat.ML},
 publisher = {Curran Associates, Inc.},
 title = {Symmetry-adapted generation of {3D} point sets for the targeted discovery of molecules},
 type = {arXiv},
 url = {http://papers.nips.cc/paper/8974-symmetry-adapted-generation-of-3d-point-sets-for-the-targeted-discovery-of-molecules.pdf},
 year = {2019}
}

@article{hadash2018estimate,
 author = {Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
 eprint = {1804.09028},
 journal = {arXiv preprint arXiv:1804.09028},
 title = {Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
 year = {2018}
}

@unpublished{Hashemi:2019fkn,
 archiveprefix = {arXiv},
 author = {Hashemi, Bobak and Amin, Nick and Datta, Kaustuv and Olivito, Dominick and Pierini, Maurizio},
 eprint = {1901.05282},
 link = {https://arxiv.org/abs/1901.05282},
 primaryclass = {hep-ex},
 slaccitation = {%%CITATION = ARXIV:1901.05282;%%},
 title = {{LHC} analysis-specific datasets with Generative Adversarial Networks},
 type = {arXiv},
 year = {2019}
}

@article{hcal_resolution,
 author = {Abdullin, S. and others},
 collaboration = {CMS HCAL},
 doi = {10.1140/epjc/s10052-008-0573-y},
 journal = {Eur. Phys. J. C},
 number = {1},
 pages = {159--171},
 reportnumber = {FERMILAB-PUB-08-246-CMS, CERN-CMS-NOTE-2006-138, CMS-NOTE-2006-138},
 title = {{Design, performance, and calibration of CMS hadron-barrel calorimeter wedges}},
 volume = {55},
 year = {2008}
}

@article{he2015deep,
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 journal = {Proceedings of the IEEE conference on computer vision and pattern recognition},
 pages = {770--778},
 title = {Deep residual learning for image recognition},
 year = {2016}
}

@misc{he2015delving,
 archiveprefix = {arXiv},
 author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
 eprint = {1502.01852},
 link = {https://arxiv.org/abs/1502.01852},
 primaryclass = {cs.CV},
 title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
 type = {arXiv},
 year = {2015}
}

@misc{he2016,
 archiveprefix = {arXiv},
 author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
 eprint = {1603.05027},
 link = {https://arxiv.org/abs/1603.05027},
 primaryclass = {cs.CV},
 title = {Identity Mappings in Deep Residual Networks},
 type = {arXiv},
 year = {2016}
}

@misc{he2016identity,
 archiveprefix = {arXiv},
 author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
 eprint = {1603.05027},
 link = {https://arxiv.org/abs/1603.05027},
 primaryclass = {cs.CV},
 title = {Identity Mappings in Deep Residual Networks},
 type = {arXiv},
 year = {2016}
}

@article{herwig,
 abstract = {A major new release of the Monte Carlo event generator Herwig++ (version 3.0) is now available. This release marks the end of distinguishing Herwig++ and HER-WIG development and therefore constitutes the first major release of version 7 of the Herwig event generator family. The new version features a number of significant improvements to the event simulation, including: built-in NLO hard process calculation for virtually all Standard Model processes, with matching to both angular-ordered and dipole shower modules via both subtractive (MC@NLO-type) and multi-plicative (Powheg-type) algorithms; QED radiation and spin correlations in the angular-ordered shower; a consistent treatment of perturbative uncertainties within the hard process and parton showering. Several of the new features will be covered in detail in accompanying publications, and an update of the manual will follow in due course.},
 archiveprefix = {arXiv},
 author = {Bellm, Johannes and others},
 doi = {10.1140/epjc/s10052-016-4018-8},
 eprint = {1512.01178},
 journal = {Eur. Phys. J. C},
 month = {04},
 number = {4},
 pages = {196},
 primaryclass = {hep-ph},
 publisher = {Springer Science and Business Media {LLC}},
 reportnumber = {CERN-PH-TH-2015-289, MAN-HEP-2015-15, IFJPAN-IV-2015-13, KA-TP-18-2015, DCPT-15-142, MCNET-15-28, IPPP-15-71, HERWIG-2015-01},
 title = {{Herwig 7.0/Herwig++ 3.0 release note}},
 url = {https://doi.org/10.1140%2Fepjc%2Fs10052-016-4018-8},
 volume = {76},
 year = {2016}
}

@inproceedings{hgcal,
 archiveprefix = {arXiv},
 author = {Martelli, Arabella},
 booktitle = {{5th Large Hadron Collider Physics Conference}},
 collaboration = {CMS},
 eprint = {1708.08234},
 link = {https://arxiv.org/abs/1708.08234},
 month = {8},
 primaryclass = {physics.ins-det},
 title = {{The CMS HGCAL detector for HL-LHC upgrade}},
 type = {arXiv},
 year = {2017}
}

@article{hgcalschematic,
 author = {Portal\`es, Louis},
 collaboration = {CMS},
 doi = {10.3390/instruments6040071},
 journal = {Instruments},
 month = {10},
 number = {4},
 pages = {71},
 reportnumber = {CMS-CR-2022-118},
 title = {{L1 Triggering on High-Granularity Information at the HL-LHC}},
 volume = {6},
 year = {2022}
}

@unpublished{hinge1,
 archiveprefix = {arXiv},
 author = {Jae Hyun Lim and Jong Chul Ye},
 eprint = {1705.02894},
 link = {https://arxiv.org/abs/1705.02894},
 primaryclass = {stat.ML},
 title = {Geometric {GAN}},
 type = {arXiv},
 year = {2017}
}

@inproceedings{hinge2,
 archiveprefix = {arXiv},
 author = {Dustin Tran and Rajesh Ranganath and David M. Blei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 eprint = {1702.08896},
 link = {https://arxiv.org/abs/1702.08896},
 pages = {5523},
 primaryclass = {stat.ML},
 publisher = {Curran Associates, Inc.},
 title = {Hierarchical Implicit Models and Likelihood-Free Variational Inference},
 type = {arXiv},
 url = {http://papers.nips.cc/paper/7136-hierarchical-implicit-models-and-likelihood-free-variational-inference.pdf},
 volume = {30},
 year = {2017}
}

@misc{hinton2015distilling,
 archiveprefix = {arXiv},
 author = {Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
 eprint = {1503.02531},
 link = {https://arxiv.org/abs/1503.02531},
 primaryclass = {stat.ML},
 title = {Distilling the Knowledge in a Neural Network},
 type = {arXiv},
 year = {2015}
}

@article{hllhc,
 archiveprefix = {arXiv},
 author = {Apollinari, G. and Br\"uning, O. and Nakamoto, T. and Rossi, Lucio},
 doi = {10.5170/CERN-2015-005.1},
 editor = {Apollinari, G and B\'ejar Alonso, I and Br\"uning, O and Lamont, M and Rossi, L},
 eprint = {1705.08830},
 journal = {CERN Yellow Rep.},
 keywords = {Accelerators and Storage Rings},
 language = {en},
 number = {5},
 pages = {1--19},
 primaryclass = {physics.acc-ph},
 publisher = {CERN},
 reportnumber = {FERMILAB-PUB-15-699-TD},
 title = {{High Luminosity Large Hadron Collider HL-LHC}},
 url = {https://cds.cern.ch/record/2120673},
 year = {2015}
}

@article{hls4ml,
 archiveprefix = {arXiv},
 author = {Duarte, Javier and others},
 doi = {10.1088/1748-0221/13/07/P07027},
 eprint = {1804.06913},
 journal = {JINST},
 number = {07},
 pages = {P07027},
 primaryclass = {physics.ins-det},
 reportnumber = {FERMILAB-PUB-18-089-E},
 slaccitation = {%%CITATION = ARXIV:1804.06913;%%},
 title = {{Fast inference of deep neural networks in FPGAs for particle physics}},
 volume = {13},
 year = {2018}
}

@misc{hls4mldata_100p,
 author = {Pierini, Maurizio and Duarte, Javier Mauricio and Tran, Nhan and Freytsis, Marat},
 doi = {10.5281/zenodo.3602254},
 month = {01},
 publisher = {Zenodo},
 title = {\texttt{hls4ml} {LHC} Jet dataset (100 particles)},
 year = {2020}
}

@misc{hls4mldata_150p,
 author = {Pierini, Maurizio and Duarte, Javier Mauricio and Tran, Nhan and Freytsis, Marat},
 doi = {10.5281/zenodo.3602260},
 publisher = {Zenodo},
 title = {\texttt{hls4ml} {LHC} Jet dataset (150 particles)},
 year = {2020}
}

@misc{hls4mldata_30p,
 author = {Pierini, Maurizio and Duarte, Javier Mauricio and Tran, Nhan and Freytsis, Marat},
 doi = {10.5281/zenodo.3601436},
 month = {01},
 publisher = {Zenodo},
 title = {\texttt{hls4ml} {LHC} Jet dataset (30 particles)},
 year = {2020}
}

@misc{hls4mldata_50p,
 author = {Pierini, Maurizio and Duarte, Javier Mauricio and Tran, Nhan and Freytsis, Marat},
 doi = {10.5281/zenodo.3601443},
 month = {01},
 publisher = {Zenodo},
 title = {\texttt{hls4ml} {LHC} Jet dataset (50 particles)},
 year = {2020}
}

@article{Hochreiter1997,
 added-at = {2016-11-15T08:49:43.000+0100},
 author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
 biburl = {https://www.bibsonomy.org/bibtex/2a4a80026d24955b267cae636aa8abe4a/dallmann},
 interhash = {0692b471c4b9ae65d00affebc09fb467},
 intrahash = {a4a80026d24955b267cae636aa8abe4a},
 journal = {Neural computation},
 keywords = {lstm rnn},
 number = {8},
 pages = {1735--1780},
 publisher = {MIT Press},
 timestamp = {2016-11-15T08:49:43.000+0100},
 title = {Long short-term memory},
 volume = {9},
 year = {1997}
}

@article{HORNIK1989359,
 abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
 author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
 doi = {10.1016/0893-6080(89)90020-8},
 issn = {0893-6080},
 journal = {Neural Networks},
 keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
 number = {5},
 pages = {359--366},
 title = {{Multilayer feedforward networks are universal approximators}},
 url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
 volume = {2},
 year = {1989}
}

@inproceedings{imagenet,
 author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
 booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
 doi = {10.1109/CVPR.2009.5206848},
 number = {},
 pages = {248--255},
 title = {ImageNet: A large-scale hierarchical image database},
 volume = {},
 year = {2009}
}

@misc{inception,
 archiveprefix = {arXiv},
 author = {Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
 eprint = {1512.00567},
 link = {https://arxiv.org/abs/1512.00567},
 primaryclass = {cs.CV},
 title = {Rethinking the Inception Architecture for Computer Vision},
 type = {arXiv},
 year = {2015}
}

@article{Janiesch_2021,
 author = {Christian Janiesch and Patrick Zschech and Kai Heinrich},
 doi = {10.1007/s12525-021-00475-2},
 journal = {Electronic Markets},
 month = {04},
 number = {3},
 pages = {685--695},
 publisher = {Springer Science and Business Media {LLC}},
 title = {Machine learning and deep learning},
 url = {https://doi.org/10.1007%2Fs12525-021-00475-2},
 volume = {31},
 year = {2021}
}

@article{Jawahar_2022,
 archiveprefix = {arXiv},
 author = {Jawahar, Pratik and Aarrestad, Thea and Chernyavskaya, Nadezda and Pierini, Maurizio and Wozniak, Kinga A. and Ngadiuba, Jennifer and Duarte, Javier and Tsan, Steven},
 doi = {10.3389/fdata.2022.803685},
 eprint = {2110.08508},
 journal = {Front. Big Data},
 month = {02},
 pages = {803685},
 primaryclass = {hep-ph},
 publisher = {Frontiers Media {SA}},
 reportnumber = {FERMILAB-PUB-21-519-CMS},
 title = {{Improving Variational Autoencoders for New Physics Detection at the LHC With Normalizing Flows}},
 url = {https://doi.org/10.3389%2Ffdata.2022.803685},
 volume = {5},
 year = {2022}
}

@article{jedinet,
 archiveprefix = {arXiv},
 author = {Moreno, Eric A. and Cerri, Olmo and Duarte, Javier M. and Newman, Harvey B. and Nguyen, Thong Q. and Periwal, Avikar and Pierini, Maurizio and Serikova, Aidana and Spiropulu, Maria and Vlimant, Jean-Roch},
 doi = {10.1140/epjc/s10052-020-7608-4},
 eprint = {1908.05318},
 journal = {Eur. Phys. J. C},
 number = {1},
 pages = {58},
 primaryclass = {hep-ex},
 reportnumber = {FERMILAB-PUB-19-360-PPD},
 slaccitation = {%%CITATION = ARXIV:1908.05318;%%},
 title = {{JEDI-net: a jet identification algorithm based on interaction networks}},
 volume = {80},
 year = {2020}
}

@inproceedings{jetflow,
 archiveprefix = {arXiv},
 author = {Benno Kaech and Dirk Kr{\"u}cker and Isabell Melzer-Pellmann and Moritz Scham and Simon Schnake},
 booktitle = {21st International Workshop on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2022)},
 eprint = {2211.13630},
 link = {https://arxiv.org/abs/2211.13630},
 location = {Bari, Italy},
 primaryclass = {hep-ex},
 title = {JetFlow: Generating Jets with Conditioned and Mass Constrained Normalising Flows},
 type = {arXiv},
 year = {2022}
}

@article{jetimages,
 archiveprefix = {arXiv},
 author = {Cogan, Josh and Kagan, Michael and Strauss, Emanuel and Schwarztman, Ariel},
 doi = {10.1007/JHEP02(2015)118},
 eprint = {1407.5675},
 issn = {1029-8479},
 journal = {JHEP},
 month = {02},
 number = {2},
 pages = {118},
 primaryclass = {hep-ph},
 publisher = {Springer Science and Business Media LLC},
 title = {{Jet-Images: Computer Vision Inspired Techniques for Jet Tagging}},
 url = {http://dx.doi.org/10.1007/JHEP02(2015)118},
 volume = {02},
 year = {2015}
}

@article{jetnet,
 archiveprefix = {arXiv},
 author = {Raghav Kansal and Javier Duarte and Hao Su and Breno Orzari and Thiago Tomei and Maurizio Pierini and Mary Touranakou and Jean-Roch Vlimant and Dimitrios Gunopulos},
 booktitle = {{35th Conference on Neural Information Processing Systems}},
 doi = {10.5281/zenodo.4834876},
 eprint = {2106.11535},
 journal = {Zenodo},
 month = {05},
 primaryclass = {cs.LG},
 title = {{JetNet}},
 version = {1.0},
 year = {2021}
}

@misc{JetNet150v2,
 author = {Kansal, Raghav and others},
 doi = {10.5281/zenodo.6975117},
 month = {08},
 publisher = {Zenodo},
 title = {JetNet150},
 url = {https://doi.org/10.5281/zenodo.6975117},
 version = {2.0.0},
 year = {2022}
}

@misc{jetneteval,
 archiveprefix = {arXiv},
 author = {Raghav Kansal and Anni Li and Javier Duarte and Nadezda Chernyavskaya and Maurizio Pierini and Breno Orzari and Thiago Tomei},
 eprint = {2211.10295},
 link = {https://doi.org/10.1103/PhysRevD.107.076017},
 primaryclass = {hep-ex},
 title = {On the Evaluation of Generative Models in High Energy Physics},
 type = {DOI},
 year = {2022}
}

@article{Kajita_2006,
 abstract = {Neutrinos are very special particles. Studies of these particles have played a crucial role in the understanding of the laws of elementary particles and their interactions. Until recently, there was no evidence that neutrinos have masses, and therefore the standard model in elementary particle physics assumed that neutrinos are massless. Small but non-zero masses of neutrinos have been discovered by studying neutrinos produced by cosmic ray interactions in the atmosphere. The small neutrino masses have profound implications for our understanding of particle physics and the universe. This paper discusses the discovery of neutrino masses.},
 author = {Kajita, T.},
 bdsk-url-1 = {https://dx.doi.org/10.1088/0034-4885/69/6/R01},
 doi = {10.1088/0034-4885/69/6/R01},
 journal = {Rept. Prog. Phys.},
 month = {may},
 number = {6},
 pages = {1607--1635},
 title = {{Discovery of neutrino oscillations}},
 url = {https://dx.doi.org/10.1088/0034-4885/69/6/R01},
 volume = {69},
 year = {2006}
}

@inproceedings{karras_2020,
 archiveprefix = {arXiv},
 author = {Tero Karras and Miika Aittala and Janne Hellsten and Samuli Laine and Jaakko Lehtinen and Timo Aila},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 eprint = {2006.06676},
 link = {https://arxiv.org/abs/2006.06676},
 pages = {12104},
 primaryclass = {cs.CV},
 publisher = {Curran Associates, Inc.},
 title = {Training Generative Adversarial Networks with Limited Data},
 type = {arXiv},
 url = {https://proceedings.neurips.cc/paper/2020/file/8d30aa96e72440759f74bd2306c1fa3d-Paper.pdf},
 volume = {33},
 year = {2020}
}

@book{kde,
 author = {Silverman, B. W.},
 publisher = {Chapman and Hall/CRC},
 title = {Density Estimation for Statistics and Data Analysis},
 year = {1986}
}

@article{Khachatryan:2014jba,
 archiveprefix = {arXiv},
 author = {Khachatryan, Vardan and others},
 collaboration = {CMS},
 doi = {10.1140/epjc/s10052-015-3351-7},
 eprint = {1412.8662},
 journal = {Eur. Phys. J. C},
 number = {5},
 pages = {212},
 primaryclass = {hep-ex},
 reportnumber = {CMS-HIG-14-009, CERN-PH-EP-2014-288},
 slaccitation = {%%CITATION = ARXIV:1412.8662;%%},
 title = {{Precise determination of the mass of the Higgs boson and tests of compatibility of its couplings with the standard model predictions using proton collisions at 7 and 8 $\,\text {TeV}$}},
 volume = {75},
 year = {2015}
}

@article{Kingma2014,
 author = {Kingma, Diederik P and Ba, Jimmy},
 journal = {arXiv preprint arXiv:1412.6980},
 title = {Adam: A method for stochastic optimization},
 year = {2014}
}

@unpublished{kingma2014auto,
 archiveprefix = {arXiv},
 author = {{Kingma}, D.~P and {Welling}, M.},
 eprint = {1312.6114},
 link = {https://arxiv.org/abs/1312.6114},
 primaryclass = {stat.ML},
 title = {Auto-Encoding Variational {Bayes}},
 type = {arXiv},
 year = {2013}
}

@misc{kitaev2020reformer,
 archiveprefix = {arXiv},
 author = {Nikita Kitaev and Łukasz Kaiser and Anselm Levskaya},
 eprint = {2001.04451},
 link = {https://arxiv.org/abs/2001.04451},
 primaryclass = {cs.LG},
 title = {Reformer: The Efficient Transformer},
 type = {arXiv},
 year = {2020}
}

@article{kobyzev_2021,
 archiveprefix = {arXiv},
 author = {Kobyzev, Ivan and Prince, Simon J. D. and Brubaker, Marcus A.},
 doi = {10.1109/tpami.2020.2992934},
 eprint = {1908.09257},
 journal = {IEEE Trans. Pattern Anal. Machine Intell.},
 month = {11},
 number = {11},
 pages = {3964--3979},
 primaryclass = {stat.ML},
 publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
 title = {{Normalizing Flows: An Introduction and Review of Current Methods}},
 url = {https://arxiv.org/abs/1908.09257},
 volume = {43},
 year = {2021}
}

@inproceedings{kohler20,
 archiveprefix = {arXiv},
 author = {K{\"{o}}hler, Jonas and Klein, Leon and Noe, Frank},
 booktitle = {Proceedings of the 37th International Conference on Machine Learning},
 editor = {III, Hal Daum{\'{e}} and Singh, Aarti},
 eprint = {2006.02425},
 link = {https://arxiv.org/abs/2006.02425},
 pages = {5361},
 pdf = {http://proceedings.mlr.press/v119/kohler20a/kohler20a.pdf},
 primaryclass = {stat.ML},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Equivariant Flows: Exact Likelihood Generative Learning for Symmetric Densities},
 type = {arXiv},
 url = {https://proceedings.mlr.press/v119/kohler20a.html},
 volume = {119},
 year = {2020}
}

@article{Komiske_2018,
 archiveprefix = {arXiv},
 author = {Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse},
 doi = {10.1007/JHEP04(2018)013},
 eprint = {1712.07124},
 journal = {JHEP},
 month = {04},
 number = {4},
 pages = {013},
 primaryclass = {hep-ph},
 publisher = {Springer Science and Business Media {LLC}},
 reportnumber = {MIT-CTP-4965},
 title = {{Energy flow polynomials: A complete linear basis for jet substructure}},
 url = {https://doi.org/10.1007%2Fjhep04%282018%29013},
 volume = {04},
 year = {2018}
}

@article{Komiske_2019,
 archiveprefix = {arXiv},
 author = {Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse},
 doi = {10.1007/JHEP01(2019)121},
 eprint = {1810.05165},
 issn = {1029-8479},
 journal = {JHEP},
 month = {January},
 number = {1},
 pages = {121},
 primaryclass = {hep-ph},
 publisher = {Springer Science and Business Media LLC},
 reportnumber = {MIT-CTP 5064},
 title = {{Energy Flow Networks: Deep Sets for Particle Jets}},
 url = {http://dx.doi.org/10.1007/JHEP01(2019)121},
 volume = {01},
 year = {2019}
}

@inproceedings{kour2014fast,
 author = {Kour, George and Saabne, Raid},
 booktitle = {Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
 doi = {10.1109/SOCPAR.2014.7008025},
 organization = {IEEE},
 pages = {312--318},
 title = {Fast classification of handwritten on-line Arabic characters},
 year = {2014}
}

@inproceedings{kour2014real,
 author = {Kour, George and Saabne, Raid},
 booktitle = {Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
 doi = {10.1109/icfhr.2014.76},
 organization = {IEEE},
 pages = {417--422},
 title = {Real-time segmentation of on-line handwritten arabic script},
 year = {2014}
}

@inproceedings{krizhevsky2012imagenet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in neural information processing systems},
 pages = {1097--1105},
 title = {Imagenet classification with deep convolutional neural networks},
 year = {2012}
}

@misc{l2attention,
 archiveprefix = {arXiv},
 author = {Hyunjik Kim and George Papamakarios and Andriy Mnih},
 eprint = {2006.04710},
 link = {https://arxiv.org/abs/2006.04710},
 primaryclass = {stat.ML},
 title = {The Lipschitz Constant of Self-Attention},
 type = {arXiv},
 year = {2021}
}

@article{lagan,
 archiveprefix = {arXiv},
 author = {de Oliveira, Luke and Paganini, Michela and Nachman, Benjamin},
 doi = {10.1007/s41781-017-0004-6},
 eprint = {1701.05927},
 journal = {Comput. Softw. Big Sci.},
 number = {1},
 pages = {4},
 primaryclass = {stat.ML},
 slaccitation = {%%CITATION = ARXIV:1701.05927;%%},
 title = {{Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis}},
 volume = {1},
 year = {2017}
}

@article{Landsberg:2015pka,
 archiveprefix = {arXiv},
 author = {Landsberg, Greg},
 doi = {10.1142/S0217732315400179},
 eprint = {1506.00024},
 journal = {Mod. Phys. Lett. A},
 number = {15},
 pages = {1540017},
 primaryclass = {hep-ex},
 title = {{Searches for Extra Spatial Dimensions with the CMS Detector at the LHC}},
 volume = {30},
 year = {2015}
}

@article{Larkoski:2017jix,
 archiveprefix = {arXiv},
 author = {Larkoski, Andrew J. and Moult, Ian and Nachman, Benjamin},
 doi = {10.1016/j.physrep.2019.11.001},
 eprint = {1709.04464},
 journal = {Phys. Rept.},
 month = {jan},
 pages = {1--63},
 primaryclass = {hep-ph},
 publisher = {Elsevier {BV}},
 title = {{Jet Substructure at the Large Hadron Collider: A Review of Recent Advances in Theory and Machine Learning}},
 url = {https://doi.org/10.1016%2Fj.physrep.2019.11.001},
 volume = {841},
 year = {2020}
}

@article{Larson_2011,
 archiveprefix = {arXiv},
 author = {Larson, D. and others},
 doi = {10.1088/0067-0049/192/2/16},
 eprint = {1001.4635},
 issn = {1538-4365},
 journal = {Astrophys. J. Suppl.},
 month = {January},
 number = {2},
 pages = {16},
 primaryclass = {astro-ph.CO},
 publisher = {American Astronomical Society},
 title = {{Seven-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Power Spectra and WMAP-Derived Parameters}},
 url = {http://dx.doi.org/10.1088/0067-0049/192/2/16},
 volume = {192},
 year = {2011}
}

@article{Layernorm,
 archiveprefix = {arXiv},
 author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1607.06450},
 eprint = {1607.06450},
 keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {7},
 primaryclass = {stat.ML},
 publisher = {arXiv},
 title = {{Layer Normalization}},
 url = {https://arxiv.org/abs/1607.06450},
 year = {2016}
}

@inbook{LeCun2012,
 abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work.},
 address = {Berlin, Heidelberg},
 author = {LeCun, Yann A. and Bottou, L{\'e}on and Orr, Genevieve B. and M{\"u}ller, Klaus-Robert},
 booktitle = {Neural Networks: Tricks of the Trade: Second Edition},
 doi = {10.1007/978-3-642-35289-8_3},
 editor = {Montavon, Gr{\'e}goire and Orr, Genevi{\`e}ve B. and M{\"u}ller, Klaus-Robert},
 isbn = {978-3-642-35289-8},
 pages = {9--48},
 publisher = {Springer Berlin Heidelberg},
 title = {Efficient BackProp},
 url = {https://doi.org/10.1007/978-3-642-35289-8_3},
 year = {2012}
}

@article{lecun2015deep,
 author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
 journal = {nature},
 number = {7553},
 pages = {436--444},
 publisher = {Nature Publishing Group},
 title = {Deep learning},
 volume = {521},
 year = {2015}
}

@techreport{Lepage:123074,
 address = {Ithaca, NY},
 author = {Lepage, G P},
 institution = {Cornell Univ. Lab. Nucl. Stud.},
 reportnumber = {CLNS-447},
 title = {{VEGAS - an adaptive multi-dimensional integration
program}},
 url = {https://cds.cern.ch/record/123074},
 year = {1980}
}

@article{LHC,
 abstract = {The Large Hadron Collider (LHC) at CERN near Geneva is the world's newest and most powerful tool for Particle Physics research. It is designed to collide proton beams with a centre-of-mass energy of 14 TeV and an unprecedented luminosity of 1034 cm−2 s−1. It can also collide heavy (Pb) ions with an energy of 2.8 TeV per nucleon and a peak luminosity of 1027 cm−2 s−1. In this paper, the machine design is described.},
 author = {Lyndon Evans and  Philip Bryant},
 doi = {10.1088/1748-0221/3/08/S08001},
 editor = {Evans, Lyndon and Bryant, Philip},
 journal = {JINST},
 month = {08},
 number = {08},
 pages = {S08001},
 publisher = {},
 title = {{LHC Machine}},
 url = {https://dx.doi.org/10.1088/1748-0221/3/08/S08001},
 volume = {3},
 year = {2008}
}

@article{LHCb:2008vvz,
 author = {Alves, Jr., A. Augusto and others},
 collaboration = {LHCb},
 doi = {10.1088/1748-0221/3/08/S08005},
 journal = {JINST},
 pages = {S08005},
 reportnumber = {LHCb-DP-2008-001},
 title = {{The LHCb Detector at the LHC}},
 volume = {3},
 year = {2008}
}

@misc{lin2018focal,
 archiveprefix = {arXiv},
 author = {Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
 eprint = {1708.02002},
 link = {https://arxiv.org/abs/1708.02002},
 primaryclass = {cs.CV},
 title = {Focal Loss for Dense Object Detection},
 type = {arXiv},
 year = {2018}
}

@article{Lipman2022FlowMF,
 author = {Yaron Lipman and Ricky T. Q. Chen and Heli Ben-Hamu and Maximilian Nickel and Matt Le},
 journal = {ArXiv},
 title = {Flow Matching for Generative Modeling},
 url = {https://api.semanticscholar.org/CorpusID:252734897},
 volume = {abs/2210.02747},
 year = {2022}
}

@inproceedings{LLama,
 author = {Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, François},
 booktitle = {Proceedings of the 37th International Conference on Machine Learning},
 title = {Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention},
 year = {2020}
}

@unpublished{LSGAN,
 archiveprefix = {arXiv},
 author = {Xudong Mao and Qing Li and Haoran Xie and Raymond Y. K. Lau and Zhen Wang},
 eprint = {1611.04076},
 link = {https://arxiv.org/abs/1611.04076},
 title = {Multi-class Generative Adversarial Networks with the {L2} Loss Function},
 type = {arXiv},
 year = {2016}
}

@misc{lsun,
 archiveprefix = {arXiv},
 author = {Fisher Yu and Ari Seff and Yinda Zhang and Shuran Song and Thomas Funkhouser and Jianxiong Xiao},
 eprint = {1506.03365},
 link = {https://arxiv.org/abs/1506.03365},
 primaryclass = {cs.CV},
 title = {LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop},
 type = {arXiv},
 year = {2015}
}

@unpublished{Lu:2020npg,
 archiveprefix = {arXiv},
 author = {Lu, Yadong and Collado, Julian and Whiteson, Daniel and Baldi, Pierre},
 eprint = {2009.14017},
 link = {https://doi.org/10.1103/PhysRevD.103.036012},
 primaryclass = {physics.data-an},
 title = {{SARM}: Sparse Autoregressive Model for Scalable Generation of Sparse Images in Particle Physics},
 type = {DOI},
 year = {2020}
}

@article{lundstringmodel,
 author = {Andersson, Bo and Gustafson, G. and Ingelman, G. and Sjostrand, T.},
 doi = {10.1016/0370-1573(83)90080-7},
 journal = {Phys. Rept.},
 pages = {31--145},
 reportnumber = {LU-TP-83-10},
 title = {{Parton Fragmentation and String Dynamics}},
 volume = {97},
 year = {1983}
}

@article{made,
 archiveprefix = {arXiv},
 author = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1705.07057},
 eprint = {1705.07057},
 keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {5},
 primaryclass = {stat.ML},
 publisher = {arXiv},
 title = {{Masked Autoregressive Flow for Density Estimation}},
 url = {https://arxiv.org/abs/1705.07057},
 year = {2017}
}

@article{Martinez:2019jlu,
 archiveprefix = {arXiv},
 author = {Arjona Mart\'\i{}nez, Jes\'us and Nguyen, Thong Q. and Pierini, Maurizio and Spiropulu, Maria and Vlimant, Jean-Roch},
 booktitle = {{19th International Workshop on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2019)}},
 doi = {10.1088/1742-6596/1525/1/012081},
 eprint = {1912.02748},
 journal = {J. Phys. Conf. Ser.},
 number = {1},
 pages = {012081},
 primaryclass = {hep-ex},
 title = {{Particle Generative Adversarial Networks for full-event simulation at the LHC and their application to pileup description}},
 volume = {1525},
 year = {2020}
}

@article{mc1,
 abstract = {The Pythia program is a standard tool for the generation of events in high-energy collisions, comprising a coherent set of physics models for the evolution from a few-body hard process to a complex multiparticle final state. It contains a library of hard processes, models for initial- and final-state parton showers, matching and merging methods between hard processes and parton showers, multiparton interactions, beam remnants, string fragmentation and particle decays. It also has a set of utilities and several interfaces to external programs. Pythia 8.2 is the second main release after the complete rewrite from Fortran to C++, and now has reached such a maturity that it offers a complete replacement for most applications, notably for LHC physics studies. The many new features should allow an improved description of data. New version program summary Program title: Pythia 8.2 Catalogue identifier: ACTU_v4_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/ACTU_v4_0.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: GNU General Public Licence, version 2 No. of lines in distributed program, including test data, etc.: 478360 No. of bytes in distributed program, including test data, etc.: 14131810 Distribution format: tar.gz Programming language: C++. Computer: Commodity PCs, Macs. Operating system: Linux, OS X; should also work on other systems. RAM: ∼10 megabytes Classification: 11.2. Does the new version supersede the previous version?: Yes Catalogue identifier of previous version: ACTU_v3_0 Journal reference of previous version: Comput. Phys. Comm. 178 (2008) 852 Nature of problem: High-energy collisions between elementary particles normally give rise to complex final states, with large multiplicities of hadrons, leptons, photons and neutrinos. The relation between these final states and the underlying physics description is not a simple one, for two main reasons. Firstly, we do not even in principle have a complete understanding of the physics. Secondly, any analytical approach is made intractable by the large multiplicities. Solution method: Complete events are generated by Monte Carlo methods. The complexity is mastered by a subdivision of the full problem into a set of simpler separate tasks. All main aspects of the events are simulated, such as hard-process selection, initial- and final-state radiation, beam remnants, fragmentation, decays, and so on. Therefore events should be directly comparable with experimentally observable ones. The programs can be used to extract physics from comparisons with existing data, or to study physics at future experiments. Reasons for new version: Improved and expanded physics models. Summary of revisions: Hundreds of new features and bug fixes, allowing improved modelling. Restrictions: Depends on the problem studied. Running time: 10–1000 events per second, depending on process studied.},
 archiveprefix = {arXiv},
 author = {Sj\"ostrand, Torbj\"orn and Ask, Stefan and Christiansen, Jesper R. and Corke, Richard and Desai, Nishita and Ilten, Philip and Mrenna, Stephen and Prestel, Stefan and Rasmussen, Christine O. and Skands, Peter Z.},
 doi = {10.1016/j.cpc.2015.01.024},
 eprint = {1410.3012},
 issn = {0010-4655},
 journal = {Comput. Phys. Commun.},
 keywords = {Event generators, Multiparticle production, Matrix elements, Parton showers, Matching and merging, Multiparton interactions, Hadronisation},
 pages = {159--177},
 primaryclass = {hep-ph},
 reportnumber = {LU-TP-14-36, MCNET-14-22, CERN-PH-TH-2014-190, FERMILAB-PUB-14-316-CD, DESY-14-178, SLAC-PUB-16122},
 title = {{An introduction to PYTHIA 8.2}},
 url = {https://www.sciencedirect.com/science/article/pii/S0010465515000442},
 volume = {191},
 year = {2015}
}

@article{mc2,
 archiveprefix = {arXiv},
 author = {Bothmann, Enrico and others},
 collaboration = {Sherpa},
 doi = {10.21468/SciPostPhys.7.3.034},
 eprint = {1905.09127},
 issue = {3},
 journal = {SciPost Phys.},
 number = {3},
 pages = {034},
 primaryclass = {hep-ph},
 publisher = {SciPost},
 reportnumber = {FERMILAB-PUB-19-218-T, SLAC-PUB-17433, IPPP/19/42, MCNET-19-11},
 title = {{Event Generation with Sherpa 2.2}},
 url = {https://scipost.org/10.21468/SciPostPhys.7.3.034},
 volume = {7},
 year = {2019}
}

@misc{mccms,
 author = {CMS Collaboration},
 title = {{CMS} Offline and Computing Public Results},
 url = {https://twiki.cern.ch/twiki/bin/view/CMSPublic/\\CMSOfflineComputingResults},
 year = {2022}
}

@article{McDonald_2005,
 archiveprefix = {arXiv},
 author = {McDonald, A. B.},
 doi = {10.1016/j.nuclphysa.2005.02.102},
 editor = {Jonson, B. and Meister, M. and Nyman, G. and Zhukov, M.},
 eprint = {nucl-ex/0412005},
 issn = {0375-9474},
 journal = {Nucl. Phys. A},
 month = {April},
 pages = {53--66},
 publisher = {Elsevier BV},
 title = {{Evidence for neutrino oscillations. I. Solar and reactor neutrinos}},
 url = {http://dx.doi.org/10.1016/j.nuclphysa.2005.02.102},
 volume = {751},
 year = {2005}
}

@misc{mdma3neurips,
 author = {Benno K\"ach and Isabell Melzer-Pellmann and Dirk Kr\"ucker},
 howpublished = {\url{https://ml4physicalsciences.github.io/2023/files/NeurIPS_ML4PS_2023_10.pdf}},
 title = {Pay Attention to Mean-Fields for Point Cloud Generation},
 url = {https://ml4physicalsciences.github.io/2023/files/NeurIPS_ML4PS_2023_10.pdf},
 year = {2023}
}

@misc{MDMA_first,
 archiveprefix = {arXiv},
 author = {Benno Käch and Isabell Melzer-Pellmann},
 eprint = {2305.15254},
 link = {https://arxiv.org/abs/2305.15254},
 primaryclass = {hep-ex},
 title = {Attention to Mean-Fields for Particle Cloud Generation},
 type = {arXiv},
 year = {2023}
}

@misc{mikuni2023caloscore,
 archiveprefix = {arXiv},
 author = {Vinicius Mikuni and Benjamin Nachman},
 eprint = {2308.03847},
 link = {https://arxiv.org/abs/2308.03847},
 primaryclass = {hep-ph},
 title = {CaloScore v2: Single-shot Calorimeter Shower Simulation with Diffusion Models},
 type = {arXiv},
 year = {2023}
}

@misc{mikuni2023fast,
 archiveprefix = {arXiv},
 author = {Vinicius Mikuni and Benjamin Nachman and Mariel Pettee},
 eprint = {2304.01266},
 link = {https://doi.org/10.1103/PhysRevD.108.036025},
 primaryclass = {hep-ph},
 title = {Fast Point Cloud Generation with Diffusion Models in High Energy Physics},
 type = {DOI},
 year = {2023}
}

@article{MinibatchOT,
 author = {Kilian Fatras and Younes Zine and Szymon Majewski and R{\'e}mi Flamary and R{\'e}mi Gribonval and Nicolas Courty},
 journal = {ArXiv},
 title = {Minibatch optimal transport distances; analysis and applications},
 url = {https://api.semanticscholar.org/CorpusID:230770198},
 volume = {abs/2101.01792},
 year = {2021}
}

@article{mlinhep,
 archiveprefix = {arXiv},
 author = {Feickert, Matthew and Nachman, Benjamin},
 copyright = {Creative Commons Attribution 4.0 International},
 doi = {10.48550/ARXIV.2102.02770},
 eprint = {2102.02770},
 keywords = {High Energy Physics - Phenomenology (hep-ph), Machine Learning (cs.LG), High Energy Physics - Experiment (hep-ex), Data Analysis, Statistics and Probability (physics.data-an), Machine Learning (stat.ML), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {2},
 primaryclass = {hep-ph},
 publisher = {arXiv},
 title = {{A Living Review of Machine Learning for Particle Physics}},
 url = {https://arxiv.org/abs/2102.02770},
 year = {2021}
}

@article{mmd,
 author = {Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alex J},
 journal = {Journal of Machine Learning Research},
 number = {Mar},
 pages = {723--773},
 title = {A kernel two-sample test},
 volume = {13},
 year = {2012}
}

@misc{MNIST,
 author = {LeCun, Yann and Cortes, Corinna},
 journal = {IEEE Signal Processing Magazine},
 number = {6},
 pages = {141--142},
 publisher = {IEEE},
 title = {{MNIST} handwritten digit database},
 url = {http://yann.lecun.com/exdb/mnist/},
 volume = {29},
 year = {2010}
}

@misc{modecollapse,
 archiveprefix = {arXiv},
 author = {Hoang Thanh-Tung and Truyen Tran},
 eprint = {1807.04015},
 link = {https://arxiv.org/abs/1807.04015},
 primaryclass = {cs.LG},
 title = {On Catastrophic Forgetting and Mode Collapse in Generative Adversarial Networks},
 type = {arXiv},
 year = {2020}
}

@phdthesis{Mohamed:456812,
 abstract = {},
 address = {Hamburg},
 author = {Mohamed, Ashraf Kasem Abdellatif},
 doi = {10.3204/PUBDB-2021-01683},
 experiment = {EXP:(DE-H253)LHC-Exp-CMS-20150101},
 pages = {194},
 publisher = {Verlag Deutsches Elektronen-Synchrotron},
 reportnumber = {DESY-THESIS-2021-005},
 school = {RWTH Aachen U., RWTH Aachen U.},
 series = {DESY-THESIS},
 title = {{Search for Dark Matter with machine learning techniques in leptonic final states and missing transverse energy at the CMS Experiment}},
 typ = {PUB:(DE-HGF)3 / PUB:(DE-HGF)11},
 url = {https://bib-pubdb1.desy.de/record/456812},
 year = {2021}
}

@misc{montfar2014number,
 archiveprefix = {arXiv},
 author = {Guido Montúfar and Razvan Pascanu and Kyunghyun Cho and Yoshua Bengio},
 eprint = {1402.1869},
 link = {https://arxiv.org/abs/1402.1869},
 primaryclass = {stat.ML},
 title = {On the Number of Linear Regions of Deep Neural Networks},
 type = {arXiv},
 year = {2014}
}

@article{mpgan,
 author = {Raghav Kansal and Javier M. Duarte and Hao Su and Breno Orzari and Thiago Tomei and Maurizio Pierini and Mary Touranakou and Jean{-}Roch Vlimant and Dimitrios Gunopoulos},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/abs-2106-11535.bib},
 eprint = {2106.11535},
 eprinttype = {arXiv},
 journal = {CoRR},
 timestamp = {Wed, 30 Jun 2021 16:14:10 +0200},
 title = {Particle Cloud Generation with Message Passing Generative Adversarial Networks},
 url = {https://arxiv.org/abs/2106.11535},
 volume = {abs/2106.11535},
 year = {2021}
}

@misc{mpgancode,
 author = {Kansal, Raghav},
 doi = {10.5281/zenodo.5598407},
 title = {{MPGAN} Code},
 url = {https://github.com/rkansal47/MPGAN/tree/neurips21}
}

@inproceedings{MPNN,
 author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
 booktitle = {Proceedings of the 34th International Conference on Machine Learning},
 editor = {Doina Precup and Yee Whye Teh},
 eprint = {1704.01212},
 numpages = {10},
 pages = {1263},
 publisher = {PMLR},
 title = {Neural Message Passing for Quantum Chemistry},
 url = {http://proceedings.mlr.press/v70/gilmer17a.html},
 volume = {70},
 year = {2017}
}

@misc{multiclassifiermetric,
 archiveprefix = {arXiv},
 author = {Sung Hak Lim and Kailash A. Raman and Matthew R. Buckley and David Shih},
 eprint = {2211.11765},
 link = {https://arxiv.org/abs/2211.11765},
 primaryclass = {astro-ph.GA},
 title = {GalaxyFlow: Upsampling Hydrodynamical Simulations for Realistic Gaia Mock Catalogs},
 type = {arXiv},
 year = {2022}
}

@article{Musella:2018rdi,
 archiveprefix = {arXiv},
 author = {Musella, Pasquale and Pandolfi, Francesco},
 doi = {10.1007/s41781-018-0015-y},
 eprint = {1805.00850},
 journal = {Comput. Softw. Big Sci.},
 number = {1},
 pages = {8},
 primaryclass = {hep-ex},
 slaccitation = {%%CITATION = ARXIV:1805.00850;%%},
 title = {{Fast and Accurate Simulation of Particle Detectors Using Generative Adversarial Networks}},
 volume = {2},
 year = {2018}
}

@misc{musicgan,
 author = {Yang, Li-Chia and Chou, Szu-Yu and Yang, Yi-Hsuan},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1703.10847},
 keywords = {Sound (cs.SD), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation},
 url = {https://arxiv.org/abs/1703.10847},
 year = {2017}
}

@misc{nakkiran2019deep,
 archiveprefix = {arXiv},
 author = {Preetum Nakkiran and Gal Kaplun and Yamini Bansal and Tristan Yang and Boaz Barak and Ilya Sutskever},
 eprint = {1912.02292},
 link = {https://arxiv.org/abs/1912.02292},
 primaryclass = {cs.LG},
 title = {Deep Double Descent: Where Bigger Models and More Data Hurt},
 type = {arXiv},
 year = {2019}
}

@article{naturegen,
 archiveprefix = {arXiv},
 author = {Otten, Sydney and Caron, Sascha and de Swart, Wieske and van Beekveld, Melissa and Hendriks, Luc and van Leeuwen, Caspar and Podareanu, Damian and Ruiz de Austri, Roberto and Verheyen, Rob},
 doi = {10.1038/s41467-021-22616-z},
 eprint = {1901.00875},
 journal = {Nature Commun.},
 number = {1},
 pages = {2985},
 primaryclass = {hep-ph},
 slaccitation = {%%CITATION = ARXIV:1901.00875;%%},
 title = {{Event Generation and Statistical Sampling for Physics with Deep Generative Models and a Density Information Buffer}},
 url = {https://arxiv.org/abs/1901.00875},
 volume = {12},
 year = {2021}
}

@article{Neyman:1933wgr,
 author = {Neyman, Jerzy and Pearson, Egon Sharpe},
 doi = {10.1098/rsta.1933.0009},
 journal = {Phil. Trans. Roy. Soc. Lond. A},
 number = {694-706},
 pages = {289--337},
 title = {{On the Problem of the Most Efficient Tests of Statistical Hypotheses}},
 volume = {231},
 year = {1933}
}

@inproceedings{nice,
 archiveprefix = {arXiv},
 author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1410.8516},
 eprint = {1410.8516},
 keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {10},
 primaryclass = {cs.LG},
 publisher = {arXiv},
 title = {{NICE: Non-linear Independent Components Estimation}},
 url = {https://arxiv.org/abs/1410.8516},
 year = {2014}
}

@article{nipstutorial,
 archiveprefix = {arXiv},
 author = {Goodfellow, Ian},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1701.00160},
 eprint = {1701.00160},
 keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {12},
 primaryclass = {cs.LG},
 publisher = {arXiv},
 title = {{NIPS 2016 Tutorial: Generative Adversarial Networks}},
 url = {https://arxiv.org/abs/1701.00160},
 year = {2016}
}

@inproceedings{NND,
 author = {Sainin, Mohd Shamrie and Alfred, Rayner},
 booktitle = {Proceedings of the 6th International Conference on Advanced Data Mining and Applications: Part I},
 doi = {10.1007/978-3-642-17316-5_11},
 pages = {114–124},
 title = {Nearest Neighbour Distance Matrix Classification},
 year = {2010}
}

@misc{NodesThesis,
 archiveprefix = {arXiv},
 author = {Patrick Kidger},
 eprint = {2202.02435},
 link = {https://arxiv.org/abs/2202.02435},
 primaryclass = {cs.LG},
 title = {On Neural Differential Equations},
 type = {arXiv},
 year = {2022}
}

@inproceedings{nsf,
 archiveprefix = {arXiv},
 author = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1906.04032},
 eprint = {1906.04032},
 keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {6},
 primaryclass = {stat.ML},
 publisher = {arXiv},
 title = {{Neural Spline Flows}},
 url = {https://arxiv.org/abs/1906.04032},
 year = {2019}
}

@misc{originalmade,
 archiveprefix = {arXiv},
 author = {Mathieu Germain and Karol Gregor and Iain Murray and Hugo Larochelle},
 eprint = {1502.03509},
 link = {https://arxiv.org/abs/1502.03509},
 primaryclass = {cs.LG},
 title = {MADE: Masked Autoencoder for Distribution Estimation},
 type = {arXiv},
 year = {2015}
}

@article{OT,
 author = {Robert J. McCann},
 journal = {Advances in Mathematics},
 pages = {153--179},
 title = {A Convexity Principle for Interacting Gases},
 url = {https://api.semanticscholar.org/CorpusID:123005604},
 volume = {128},
 year = {1997}
}

@inproceedings{OTCNF,
 author = {Alexander Tong and Nikolay Malkin and Guillaume Huguet and Yanlei Zhang and Jarrid Rector-Brooks and Kilian Fatras and Guy Wolf and Yoshua Bengio},
 title = {Improving and generalizing flow-based generative models with minibatch optimal transport},
 url = {https://api.semanticscholar.org/CorpusID:259847293},
 year = {2023}
}

@misc{otherattentionthing,
 author = {Keles, Feyza Duman and Wijewardena, Pruthuvi Mahesakya and Hegde, Chinmay},
 copyright = {Creative Commons Attribution Share Alike 4.0 International},
 doi = {10.48550/ARXIV.2209.04881},
 eprint = {2209.04881},
 keywords = {Machine Learning (cs.LG), Computational Complexity (cs.CC), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {On The Computational Complexity of Self-Attention},
 url = {https://arxiv.org/abs/2209.04881},
 year = {2022}
}

@article{Paganini:2017hrr,
 archiveprefix = {arXiv},
 author = {Paganini, Michela and de Oliveira, Luke and Nachman, Benjamin},
 doi = {10.1103/PhysRevLett.120.042003},
 eprint = {1705.02355},
 journal = {Phys. Rev. Lett.},
 number = {4},
 pages = {042003},
 primaryclass = {hep-ex},
 slaccitation = {%%CITATION = ARXIV:1705.02355;%%},
 title = {{Accelerating Science with Generative Adversarial Networks: An Application to 3D Particle Showers in Multilayer Calorimeters}},
 volume = {120},
 year = {2018}
}

@article{papama19,
 archiveprefix = {arXiv},
 author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1912.02762},
 eprint = {1912.02762},
 keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {12},
 primaryclass = {stat.ML},
 publisher = {arXiv},
 title = {{Normalizing Flows for Probabilistic Modeling and Inference}},
 url = {https://arxiv.org/abs/1912.02762},
 year = {2019}
}

@misc{Par04,
 collaboration = {\textsc{Geant4}},
 date = {08.03.2022},
 title = {{Par04 example}},
 url = {https://gitlab.cern.ch/geant4/geant4/-/tree/master/examples/extended/parameterisations/Par04},
 version = {11.0}
}

@article{particlenet,
 archiveprefix = {arXiv},
 author = {Qu, Huilin and Gouskos, Loukas},
 doi = {10.1103/PhysRevD.101.056019},
 eprint = {1902.08570},
 journal = {Phys. Rev. D},
 month = {03},
 number = {5},
 pages = {056019},
 primaryclass = {hep-ph},
 publisher = {American Physical Society ({APS})},
 title = {{ParticleNet: Jet Tagging via Particle Clouds}},
 url = {https://doi.org/10.1103%2Fphysrevd.101.056019},
 volume = {101},
 year = {2020}
}

@article{parton,
 author = {Andersson, Bo and Gustafson, G. and Ingelman, G. and Sjostrand, T.},
 doi = {10.1016/0370-1573(83)90080-7},
 issn = {0370-1573},
 journal = {Phys. Rept.},
 number = {2},
 pages = {31--145},
 reportnumber = {LU-TP-83-10},
 title = {{Parton Fragmentation and String Dynamics}},
 url = {https://www.sciencedirect.com/science/article/pii/0370157383900807},
 volume = {97},
 year = {1983}
}

@article{Pata_2023,
 archiveprefix = {arXiv},
 author = {Pata, Joosep and Duarte, Javier and Mokhtar, Farouk and Wulff, Eric and Yoo, Jieun and Vlimant, Jean-Roch and Pierini, Maurizio and Girone, Maria},
 bdsk-url-1 = {https://dx.doi.org/10.1088/1742-6596/2438/1/012100},
 collaboration = {CMS},
 doi = {10.1088/1742-6596/2438/1/012100},
 eprint = {2203.00330},
 journal = {J. Phys. Conf. Ser.},
 month = {02},
 number = {1},
 pages = {012100},
 primaryclass = {physics.data-an},
 publisher = {IOP Publishing},
 reportnumber = {CMS-CR-2022-021},
 title = {{Machine Learning for Particle Flow Reconstruction at CMS}},
 url = {https://dx.doi.org/10.1088/1742-6596/2438/1/012100},
 volume = {2438},
 year = {2023}
}

@misc{pcdroid,
 archiveprefix = {arXiv},
 author = {Matthew Leigh and Debajyoti Sengupta and John Andrew Raine and Guillaume Quétant and Tobias Golling},
 eprint = {2307.06836},
 link = {https://doi.org/10.1103/PhysRevD.109.012010},
 primaryclass = {hep-ex},
 title = {PC-Droid: Faster diffusion and improved quality for particle cloud generation},
 type = {DOI},
 year = {2023}
}

@inproceedings{pcgan,
 author = {Li, Chun-Liang and Zaheer, Manzil and Zhang, Yang and Poczos, Barnabas and Salakhutdinov, Ruslan},
 booktitle = {2019 ICLR Workshop Deep Generative Models for Highly Structured Data},
 eprint = {1810.05795},
 title = {Point cloud {GAN}},
 url = {https://openreview.net/forum?id=S1xim8UFuV},
 year = {2018}
}

@article{pchip,
 abstract = { A method is described for producing monotone piecewise cubic interpolants to monotone data which is completely local and which is extremely simple to implement. },
 author = {Fritsch, F. N. and Butland, J.},
 bdsk-url-1 = {https://doi.org/10.1137/0905021},
 doi = {10.1137/0905021},
 eprint = {https://doi.org/10.1137/0905021},
 journal = {SIAM Journal on Scientific and Statistical Computing},
 number = {2},
 pages = {300-304},
 title = {A Method for Constructing Local Monotone Piecewise Cubic Interpolants},
 url = {https://doi.org/10.1137/0905021},
 volume = {5},
 year = {1984}
}

@misc{pcjedi,
 archiveprefix = {arXiv},
 author = {Matthew Leigh and Debajyoti Sengupta and Guillaume Quétant and John Andrew Raine and Knut Zoch and Tobias Golling},
 eprint = {2303.05376},
 link = {https://doi.org/10.21468/SciPostPhys.16.1.018},
 primaryclass = {hep-ph},
 title = {PC-JeDi: Diffusion for Particle Cloud Generation in High Energy Physics},
 type = {DOI},
 year = {2023}
}

@article{pedro19,
 author = {Pedro, Kevin},
 collaboration = {CMS},
 doi = {10.1051/epjconf/201921402036},
 editor = {Forti, A. and Betev, L. and Litmaath, M. and Smirnova, O. and Hristov, P.},
 journal = {EPJ Web Conf.},
 pages = {02036},
 reportnumber = {FERMILAB-CONF-18-784-SCD, CMS-CR-2018-211},
 title = {{Current and future performance of the CMS simulation}},
 url = {https://doi.org/10.1051/epjconf/201921402036},
 volume = {214},
 year = {2019}
}

@book{PeskinSchroeder1995,
 author = {Peskin, Michael E. and Schroeder, Daniel V.},
 isbn = {978-0-201-50397-5},
 note = {},
 publisher = {Westview Press},
 title = {An Introduction to Quantum Field Theory},
 year = {1995}
}

@article{PhysRevLett.81.1562,
 archiveprefix = {arXiv},
 author = {Fukuda, Y. and others},
 collaboration = {Super-Kamiokande},
 doi = {10.1103/PhysRevLett.81.1562},
 eprint = {hep-ex/9807003},
 issue = {8},
 journal = {Phys. Rev. Lett.},
 month = {Aug},
 numpages = {0},
 pages = {1562--1567},
 publisher = {American Physical Society},
 reportnumber = {BU-98-17, ICRR-REPORT-422-98-18, UCI-98-8, KEK-PREPRINT-98-95, LSU-HEPA-5-98, UMD-98-003, SBHEP-98-5, TKU-PAP-98-06, TIT-HPE-98-09},
 title = {{Evidence for oscillation of atmospheric neutrinos}},
 url = {https://link.aps.org/doi/10.1103/PhysRevLett.81.1562},
 volume = {81},
 year = {1998}
}

@book{picard,
 author = {Coddington, A. and Levinson, N.},
 isbn = {9780070992566},
 lccn = {54011260},
 publisher = {McGraw-Hill},
 series = {International series in pure and applied mathematics},
 title = {Theory of Ordinary Differential Equations},
 url = {https://books.google.de/books?id=8QjvnT2hmqwC},
 year = {1955}
}

@article{PINN,
 abstract = {We introduce physics-informed neural networks -- neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge--Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction--diffusion systems, and the propagation of nonlinear shallow-water waves.},
 archiveprefix = {arXiv},
 author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
 bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
 bdsk-url-2 = {https://doi.org/10.1016/j.jcp.2018.10.045},
 doi = {10.1016/j.jcp.2018.10.045},
 eprint = {1711.10561},
 issn = {0021-9991},
 journal = {J. Comput. Phys.},
 keywords = {Data-driven scientific computing, Machine learning, Predictive modeling, Runge--Kutta methods, Nonlinear dynamics},
 pages = {686--707},
 primaryclass = {cs.AI},
 title = {{Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations}},
 url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
 volume = {378},
 year = {2019}
}

@misc{pix2pix,
 author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1611.07004},
 keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Image-to-Image Translation with Conditional Adversarial Networks},
 url = {https://arxiv.org/abs/1611.07004},
 year = {2016}
}

@inproceedings{pmlr-v70-gilmer17a,
 archiveprefix = {arXiv},
 author = {Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
 editor = {Doina Precup and Yee Whye Teh},
 eprint = {1704.01212},
 link = {https://arxiv.org/abs/1704.01212},
 pages = {1263},
 pdf = {http://proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf},
 primaryclass = {cs.LG},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Neural Message Passing for Quantum Chemistry},
 type = {arXiv},
 url = {http://proceedings.mlr.press/v70/gilmer17a.html},
 volume = {70},
 year = {2017}
}

@misc{pointdiffusion,
 archiveprefix = {arXiv},
 author = {Erik Buhmann and Sascha Diefenbacher and Engin Eren and Frank Gaede and Gregor Kasieczka and Anatolii Korol and William Korcari and Katja Krüger and Peter McKeown},
 eprint = {2305.04847},
 link = {https://doi.org/10.1088/1748-0221/18/11/P11025},
 primaryclass = {physics.ins-det},
 title = {CaloClouds: Fast Geometry-Independent Highly-Granular Calorimeter Simulation},
 type = {DOI},
 year = {2023}
}

@misc{pointdiffusionorig,
 archiveprefix = {arXiv},
 author = {Shitong Luo and Wei Hu},
 eprint = {2103.01458},
 link = {https://arxiv.org/abs/2103.01458},
 primaryclass = {cs.CV},
 title = {Diffusion Probabilistic Models for 3D Point Cloud Generation},
 type = {arXiv},
 year = {2021}
}

@inproceedings{pointflow,
 archiveprefix = {arXiv},
 author = {Guandao Yang and Xun Huang and Zekun Hao and Ming-Yu Liu and Serge Belongie and Bharath Hariharan},
 booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
 doi = {10.1109/ICCV.2019.00464},
 eprint = {1906.12320},
 pages = {4540},
 primaryclass = {cs.CV},
 title = {{PointFlow}: {3D} Point Cloud Generation with Continuous Normalizing Flows},
 year = {2019}
}

@inproceedings{pointnet,
 author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
 booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 doi = {10.1109/cvpr.2017.16},
 month = {July},
 title = {{PointNet}: Deep Learning on Point Sets for {3D} Classification and Segmentation},
 year = {2017}
}

@article{PRECHELT199749,
 abstract = {Neural network pruning methods on the level of individual network parameters (e.g. connection weights) can improve generalization, as is shown in this empirical study. However, an open problem in the pruning methods known today (e.g. OBD, OBS, autoprune, epsiprune) is the selection of the number of parameters to be removed in each pruning step (pruning strength). This work presents a pruning method lprune that automatically adapts the pruning strength to the evolution of weights and loss of generalization during training. The method requires no algorithm parameter adjustment by the user. Results of statistical significance tests comparing autoprune, lprune, and static networks with early stopping are given, based on extensive experimentation with 14 different problems. The results indicate that training with pruning is often significantly better and rarely significantly worse than training with early stopping without pruning. Furthermore, lprune is often superior to autoprune (which is superior to OBD) on diagnosis tasks unless severe pruning early in the training process is required.},
 author = {Lutz Prechelt},
 bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0925231296000549},
 bdsk-url-2 = {https://doi.org/10.1016/S0925-2312(96)00054-9},
 doi = {https://doi.org/10.1016/S0925-2312(96)00054-9},
 issn = {0925-2312},
 journal = {Neurocomputing},
 keywords = {Empirical study, Pruning, Early stopping, Generalization},
 number = {1},
 pages = {49--61},
 title = {Connection pruning with static and adaptive pruning schedules},
 url = {https://www.sciencedirect.com/science/article/pii/S0925231296000549},
 volume = {16},
 year = {1997}
}

@article{pythia,
 archiveprefix = {arXiv},
 author = {Sj\"ostrand, Torbj\"orn and Ask, Stefan and Christiansen, Jesper R. and Corke, Richard and Desai, Nishita and Ilten, Philip and Mrenna, Stephen and Prestel, Stefan and Rasmussen, Christine O. and Skands, Peter Z.},
 doi = {10.1016/j.cpc.2015.01.024},
 eprint = {1410.3012},
 journal = {Comput. Phys. Commun.},
 month = {jun},
 pages = {159--177},
 primaryclass = {hep-ph},
 primaryclassremove = {hep-ph},
 publisher = {Elsevier {BV}},
 reportnumber = {LU-TP-14-36, MCNET-14-22, CERN-PH-TH-2014-190, FERMILAB-PUB-14-316-CD, DESY-14-178, SLAC-PUB-16122},
 slaccitation = {%%CITATION = ARXIV:1410.3012;%%},
 title = {{An introduction to PYTHIA 8.2}},
 url = {https://doi.org/10.1016%2Fj.cpc.2015.01.024},
 volume = {191},
 year = {2015}
}

@incollection{pytorch,
 author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
 booktitle = {Advances in Neural Information Processing Systems 32},
 pages = {8024--8035},
 publisher = {Curran Associates, Inc.},
 title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
 url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
 year = {2019}
}

@article{realnvp,
 archiveprefix = {arXiv},
 author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1605.08803},
 eprint = {1605.08803},
 keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 month = {5},
 primaryclass = {cs.LG},
 publisher = {arXiv},
 title = {{Density estimation using Real NVP}},
 url = {https://arxiv.org/abs/1605.08803},
 year = {2016}
}

@inproceedings{rezende,
 author = {Rezende, Danilo and Mohamed, Shakir},
 booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
 eprint = {1505.05770},
 pages = {1530--1538},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Variational Inference with Normalizing Flows},
 url = {https://proceedings.mlr.press/v37/rezende15.html},
 volume = {37},
 year = {2015}
}

@misc{rezendeML,
 author = {Gemici, Mevlana C. and Rezende, Danilo and Mohamed, Shakir},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1611.02304},
 keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Statistics Theory (math.ST), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
 publisher = {arXiv},
 title = {Normalizing Flows on Riemannian Manifolds},
 url = {https://arxiv.org/abs/1611.02304},
 year = {2016}
}

@inproceedings{rgan,
 abstract = {Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep AutoEncoder (AE) network with state-of-the-art reconstruction quality and generalization ability. The learned representations outperform existing methods on 3D recognition tasks and enable shape editing via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation, as well as shape completion. We perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space of our AEs, and Gaussian Mixture Models (GMMs). To quantitatively evaluate generative models we introduce measures of sample fidelity and diversity based on matchings between sets of point clouds. Interestingly, our evaluation of generalization, fidelity and diversity reveals that GMMs trained in the latent space of our AEs yield the best results overall.},
 author = {Achlioptas, Panos and Diamanti, Olga and Mitliagkas, Ioannis and Guibas, Leonidas},
 booktitle = {Proceedings of the 35th International Conference on Machine Learning},
 editor = {Dy, Jennifer and Krause, Andreas},
 eprint = {1707.02392},
 month = {10--15 Jul},
 pages = {40},
 pdf = {http://proceedings.mlr.press/v80/achlioptas18a/achlioptas18a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning Representations and Generative Models for 3{D} Point Clouds},
 url = {http://proceedings.mlr.press/v80/achlioptas18a.html},
 volume = {80},
 year = {2018}
}

@misc{rmsprop,
 author = {Tijmen Tieleman and Geoffery Hinton},
 title = {Rmsprop gradient optimization},
 url = {http://www. cs. toronto. edu/tijmen/csc321/slides/lecture_slides_lec6. pdf},
 year = {2014}
}

@article{Robbins1951,
 author = {Robbins, Herbert and Monro, Sutton},
 journal = {The Annals of Mathematical Statistics},
 number = {3},
 pages = {400--407},
 publisher = {Institute of Mathematical Statistics},
 title = {Stochastic Estimation of the Maximum of a Regression Function},
 volume = {22},
 year = {1951}
}

@article{roc,
 author = {Fawcett, Tom},
 doi = {10.1016/j.patrec.2005.10.010},
 journal = {Pattern Recognition Letters},
 number = {8},
 pages = {861--874},
 publisher = {Elsevier},
 title = {An introduction to ROC analysis},
 volume = {27},
 year = {2006}
}

@inproceedings{rprop,
 author = {Riedmiller, M. and Braun, H.},
 booktitle = {IEEE International Conference on Neural Networks},
 doi = {10.1109/ICNN.1993.298623},
 number = {},
 pages = {586--591 vol.1},
 title = {A direct adaptive method for faster backpropagation learning: the RPROP algorithm},
 volume = {},
 year = {1993}
}

@book{rubinsteinduality,
 author = {Villani, C.},
 isbn = {9783540710509},
 lccn = {2008932183},
 publisher = {Springer Berlin Heidelberg},
 series = {Grundlehren der mathematischen Wissenschaften},
 title = {Optimal Transport: Old and New},
 url = {https://books.google.de/books?id=hV8o5R7\_5tkC},
 year = {2008}
}

@article{Rumelhart1986,
 abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden'units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
 author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
 doi = {10.1038/323533a0},
 journal = {Nature},
 number = {6088},
 pages = {533--536},
 title = {{Learning representations by back-propagating errors}},
 url = {https://doi.org/10.1038/323533a0},
 volume = {323},
 year = {1986}
}

@misc{russakovsky2014imagenet,
 archiveprefix = {arXiv},
 author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
 eprint = {1409.0575},
 link = {https://arxiv.org/abs/1409.0575},
 primaryclass = {cs.CV},
 title = {ImageNet Large Scale Visual Recognition Challenge},
 type = {arXiv},
 year = {2014}
}

@inproceedings{Salamani:2645142,
 author = {Salamani, Dalila and Gadatsch, Stefan and Golling, Tobias and Stewart, Graeme Andrew and Ghosh, Aishik and Rousseau, David and Hasib, Ahmed and Schaarschmidt, Jana},
 booktitle = {{14th International Conference on e-Science}},
 doi = {10.1109/eScience.2018.00091},
 pages = {348},
 reportnumber = {ATL-SOFT-SLIDE-2018-983},
 title = {{Deep Generative Models for Fast Shower Simulation in ATLAS}},
 url = {http://cds.cern.ch/record/2645142},
 year = {2018}
}

@article{sarm,
 archiveprefix = {arXiv},
 author = {Lu, Yadong and Collado, Julian and Whiteson, Daniel and Baldi, Pierre},
 doi = {10.1103/PhysRevD.103.036012},
 eprint = {2009.14017},
 journal = {Phys. Rev. D},
 number = {3},
 pages = {036012},
 primaryclass = {physics.data-an},
 title = {{Sparse autoregressive models for scalable generation of sparse images in particle physics}},
 volume = {103},
 year = {2021}
}

@misc{scham2023deeptreegan,
 archiveprefix = {arXiv},
 author = {Moritz Alfons Wilhelm Scham and Dirk Krücker and Benno Käch and Kerstin Borras},
 eprint = {2311.12616},
 link = {https://arxiv.org/abs/2311.12616},
 primaryclass = {hep-ex},
 title = {DeepTreeGAN: Fast Generation of High Dimensional Point Clouds},
 type = {arXiv},
 year = {2023}
}

@inproceedings{schnake2022,
 author = {Simon Schnake and Dirk Krücker and Kerstin Borras},
 booktitle = {36th annual conference on Neural Information Processing Systems (NeurIPS)},
 series = {Machine Learning and the Physical Sciences},
 title = {Generating Calorimeter Showers as Point Clouds},
 year = {2022}
}

@inproceedings{Schrdinger1932SurLT,
 author = {Erwin Schr{\"o}dinger},
 title = {Sur la th{\'e}orie relativiste de l'{\'e}lectron et l'interpr{\'e}tation de la m{\'e}canique quantique},
 url = {https://api.semanticscholar.org/CorpusID:123681701},
 year = {1932}
}

@article{scipy,
 adsurl = {https://rdcu.be/b08Wh},
 archiveprefix = {arXiv},
 author = {Virtanen, Pauli and others},
 doi = {10.1038/s41592-019-0686-2},
 eprint = {1907.10121},
 journal = {Nature Meth.},
 pages = {261},
 primaryclass = {cs.MS},
 title = {{SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python}},
 volume = {17},
 year = {2020}
}

@article{Scott1979OnOA,
 author = {David W. Scott},
 journal = {Biometrika},
 pages = {605-610},
 title = {On optimal and data based histograms},
 url = {https://api.semanticscholar.org/CorpusID:59500098},
 volume = {66},
 year = {1979}
}

@misc{sde,
 archiveprefix = {arXiv},
 author = {Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
 eprint = {2011.13456},
 link = {https://arxiv.org/abs/2011.13456},
 primaryclass = {cs.LG},
 title = {Score-Based Generative Modeling through Stochastic Differential Equations},
 type = {arXiv},
 year = {2021}
}

@misc{settransformer,
 archiveprefix = {arXiv},
 author = {Juho Lee and Yoonho Lee and Jungtaek Kim and Adam R. Kosiorek and Seungjin Choi and Yee Whye Teh},
 eprint = {1810.00825},
 link = {https://arxiv.org/abs/1810.00825},
 primaryclass = {cs.LG},
 title = {Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks},
 type = {arXiv},
 year = {2019}
}

@article{sgd,
 author = {Herbert Robbins and Sutton Monro},
 bdsk-url-1 = {https://doi.org/10.1214/aoms/1177729586},
 doi = {10.1214/aoms/1177729586},
 journal = {The Annals of Mathematical Statistics},
 number = {3},
 pages = {400 -- 407},
 publisher = {Institute of Mathematical Statistics},
 title = {{A Stochastic Approximation Method}},
 url = {https://doi.org/10.1214/aoms/1177729586},
 volume = {22},
 year = {1951}
}

@inproceedings{sgk_sc2020,
 author = {Trevor Gale and Matei Zaharia and Cliff Young and Erich Elsen},
 booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, {SC} 2020},
 title = {Sparse {GPU} Kernels for Deep Learning},
 year = {2020}
}

@inproceedings{ShapeGF,
 address = {Cham},
 archiveprefix = {arXiv},
 author = {Cai, Ruojin and Yang, Guandao and Averbuch-Elor, Hadar and Hao, Zekun and Belongie, Serge and Snavely, Noah and Hariharan, Bharath},
 booktitle = {2020 European Conference on Computer Vision (ECCV)},
 doi = {10.1007/978-3-030-58580-8_22},
 editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
 eprint = {2008.06520},
 isbn = {978-3-030-58580-8},
 pages = {364},
 primaryclass = {cs.CV},
 title = {Learning Gradient Fields for Shape Generation},
 year = {2020}
}

@techreport{shapenet,
 author = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
 eprint = {1512.03012},
 primaryclass = {cs.GR},
 title = {{ShapeNet}: An Information-Rich {3D} Model Repository},
 type = {{Technical Report}},
 year = {2015}
}

@misc{silu,
 archiveprefix = {arXiv},
 author = {Stefan Elfwing and Eiji Uchibe and Kenji Doya},
 eprint = {1702.03118},
 link = {https://arxiv.org/abs/1702.03118},
 primaryclass = {cs.LG},
 title = {Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning},
 type = {arXiv},
 year = {2017}
}

@article{Sirunyan:2020lcu,
 archiveprefix = {arXiv},
 author = {Sirunyan, Albert M and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/15/06/P06005},
 eprint = {2004.08262},
 journal = {JINST},
 number = {06},
 pages = {P06005},
 primaryclass = {hep-ex},
 reportnumber = {CMS-JME-18-002, CERN-EP-2020-037},
 title = {{Identification of heavy, energetic, hadronically decaying particles using machine-learning techniques}},
 volume = {15},
 year = {2020}
}

@article{Sirunyan_2018,
 archiveprefix = {arXiv},
 author = {Sirunyan, A. M. and others},
 collaboration = {CMS},
 doi = {10.1088/1748-0221/13/05/P05011},
 eprint = {1712.07158},
 journal = {JINST},
 month = {05},
 number = {05},
 pages = {P05011},
 primaryclass = {physics.ins-det},
 publisher = {{IOP} Publishing},
 reportnumber = {CMS-BTV-16-002, CERN-EP-2017-326},
 title = {{Identification of heavy-flavour jets with the CMS detector in pp collisions at 13 TeV}},
 url = {https://doi.org/10.1088%2F1748-0221%2F13%2F05%2Fp05011},
 volume = {13},
 year = {2018}
}

@article{Skands:2014pea,
 archiveprefix = {arXiv},
 author = {Skands, Peter and Carrazza, Stefano and Rojo, Juan},
 doi = {10.1140/epjc/s10052-014-3024-y},
 eprint = {1404.5630},
 journal = {Eur. Phys. J. C},
 number = {8},
 pages = {3024},
 primaryclass = {hep-ph},
 reportnumber = {CERN-PH-TH-2014-069, MCNET-14-08, OUTP-14-05P},
 title = {{Tuning PYTHIA 8.1: the Monash 2013 Tune}},
 volume = {74},
 year = {2014}
}

@techreport{Software:2815292,
 address = {Geneva},
 author = {CMS Offline Software and Computing},
 institution = {CERN},
 reportnumber = {CMS-NOTE-2022-008, CERN-CMS-NOTE-2022-008},
 title = {{CMS Phase-2 Computing Model: Update Document}},
 url = {https://cds.cern.ch/record/2815292},
 year = {2022}
}

@misc{spectralnorm,
 archiveprefix = {arXiv},
 author = {Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
 booktitle = {6th International Conference on Learning Representations},
 eprint = {1802.05957},
 link = {https://arxiv.org/abs/1802.05957},
 primaryclass = {cs.LG},
 title = {Spectral Normalization for Generative Adversarial Networks},
 type = {arXiv},
 url = {https://openreview.net/forum?id=B1QRgziT-},
 year = {2018}
}

@misc{stylegan,
 archiveprefix = {arXiv},
 author = {Tero Karras and Samuli Laine and Timo Aila},
 eprint = {1812.04948},
 link = {https://arxiv.org/abs/1812.04948},
 primaryclass = {cs.NE},
 title = {A Style-Based Generator Architecture for Generative Adversarial Networks},
 type = {arXiv},
 year = {2019}
}

@article{subjettiness,
 archiveprefix = {arXiv},
 author = {Thaler, Jesse and Van Tilburg, Ken},
 doi = {10.1007/JHEP03(2011)015},
 eprint = {1011.2268},
 journal = {JHEP},
 pages = {015},
 primaryclass = {hep-ph},
 reportnumber = {MIT-CTP-4191},
 slaccitation = {%%CITATION = ARXIV:1011.2268;%%},
 title = {{Identifying Boosted Objects with N-subjettiness}},
 volume = {03},
 year = {2011}
}

@inproceedings{superpixels,
 address = {New York, NY},
 archiveprefix = {arXiv},
 author = {Federico Monti and Davide Boscaini and Jonathan Masci and Emanuele Rodol{\`{a}} and Jan Svoboda and Michael M. Bronstein},
 booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 doi = {10.1109/CVPR.2017.576},
 eprint = {1611.08402},
 pages = {5425},
 primaryclass = {cs.CV},
 publisher = {IEEE},
 title = {Geometric deep learning on graphs and manifolds using mixture model {CNNs}},
 year = {2017}
}

@misc{symmetryequivariance,
 archiveprefix = {arXiv},
 author = {Taco S. Cohen and Max Welling},
 eprint = {1602.07576},
 link = {https://arxiv.org/abs/1602.07576},
 primaryclass = {cs.LG},
 title = {Group Equivariant Convolutional Networks},
 type = {arXiv},
 year = {2016}
}

@article{t5qqqqWW,
 abstract = {A search for supersymmetry is presented in events with a single charged lepton, electron or muon, and multiple hadronic jets. The data correspond to an integrated luminosity of 138 fb−1 of proton-proton collisions at a center-of-mass energy of 13 TeV, recorded by the CMS experiment at the CERN LHC. The search targets gluino pair production, where the gluinos decay into final states with the lightest supersymmetric particle (LSP) and either a top quark-antiquark ({\$}{\$} {$\backslash$}textrm{\{}t{\}}{$\backslash$}overline{\{}{$\backslash$}textrm{\{}t{\}}{\}} {\$}{\$}) pair, or a light-flavor quark-antiquark ({\$}{\$} {$\backslash$}textrm{\{}q{\}}{$\backslash$}overline{\{}{$\backslash$}textrm{\{}q{\}}{\}} {\$}{\$}) pair and a virtual or on-shell W boson. The main backgrounds, {\$}{\$} {$\backslash$}textrm{\{}t{\}}{$\backslash$}overline{\{}{$\backslash$}textrm{\{}t{\}}{\}} {\$}{\$}pair and W+jets production, are suppressed by requirements on the azimuthal angle between the momenta of the lepton and of its reconstructed parent W boson candidate, and by top quark and W boson identification based on a machine-learning technique. The number of observed events is consistent with the expectations from standard model processes. Limits are evaluated on supersymmetric particle masses in the context of two simplified models of gluino pair production. Exclusions for gluino masses reach up to 2120 (2050) GeV at 95{\%} confidence level for a model with gluino decay to a {\$}{\$} {$\backslash$}textrm{\{}t{\}}{$\backslash$}overline{\{}{$\backslash$}textrm{\{}t{\}}{\}} {\$}{\$}pair (a {\$}{\$} {$\backslash$}textrm{\{}q{\}}{$\backslash$}overline{\{}{$\backslash$}textrm{\{}q{\}}{\}} {\$}{\$}pair and a W boson) and the LSP. For the same models, limits on the mass of the LSP reach up to 1250 (1070) GeV.},
 archiveprefix = {arXiv},
 author = {Tumasyan, Armen and others},
 bdsk-url-1 = {https://doi.org/10.1007/JHEP09(2023)149},
 collaboration = {CMS},
 date = {2023/09/22},
 date-added = {2024-02-27 13:02:02 +0100},
 date-modified = {2024-02-27 13:02:02 +0100},
 doi = {10.1007/JHEP09(2023)149},
 eprint = {2211.08476},
 id = {Tumasyan2023},
 isbn = {1029-8479},
 journal = {JHEP},
 number = {9},
 pages = {149},
 primaryclass = {hep-ex},
 reportnumber = {CMS-SUS-21-007, CERN-EP-2022-169},
 title = {{Search for supersymmetry in final states with a single electron or muon using angular correlations and heavy-object identification in proton-proton collisions at $ \sqrt{s} $ = 13 TeV}},
 url = {https://doi.org/10.1007/JHEP09(2023)149},
 volume = {09},
 year = {2023}
}

@article{tabak,
 author = {Tabak, E. G. and Turner, Cristina V.},
 doi = {10.1002/cpa.21423},
 journal = {Commun. Pure Appl. Math.},
 number = {2},
 pages = {145--164},
 title = {{A Family of Nonparametric Density Estimation Algorithms}},
 volume = {66},
 year = {2013}
}

@article{TASSO:1979zyf,
 author = {Brandelik, R. and others},
 collaboration = {TASSO},
 doi = {10.1016/0370-2693(79)90830-X},
 journal = {Phys. Lett. B},
 pages = {243--249},
 reportnumber = {DESY-79-53},
 title = {{Evidence for Planar Events in e+ e- Annihilation at High-Energies}},
 volume = {86},
 year = {1979}
}

@misc{tishby2015deep,
 archiveprefix = {arXiv},
 author = {Naftali Tishby and Noga Zaslavsky},
 eprint = {1503.02406},
 link = {https://arxiv.org/abs/1503.02406},
 primaryclass = {cs.LG},
 title = {Deep Learning and the Information Bottleneck Principle},
 type = {arXiv},
 year = {2015}
}

@misc{topquark,
 author = {Kansal, Raghav and Duarte, Javier and Su, Hao and Orzari, Breno and Tomei, Thiago and Pierini, Maurizio and Touranakou, Mary and Vlimant, Jean-Roch and Gunopulos, Dimitrios},
 doi = {10.5281/zenodo.6302454},
 month = {May},
 publisher = {Zenodo},
 title = {JetNet(1.1)[Topquark]},
 url = {https://doi.org/10.5281/zenodo.6302454},
 version = {1.1},
 year = {2021}
}

@article{towardsprinciple,
 author = {Arjovsky, Martin and Bottou, Léon},
 journal = {stat},
 month = {01},
 pages = {},
 title = {Towards Principled Methods for Training Generative Adversarial Networks},
 volume = {1050},
 year = {2017}
}

@article{tran_2020,
 archiveprefix = {arXiv},
 author = {Ngoc-Trung Tran and Viet-Hung Tran and Ngoc-Bao Nguyen and Trung-Kien Nguyen and Ngai-Man Cheung},
 doi = {10.1109/tip.2021.3049346},
 eprint = {2006.05338},
 issn = {1941-0042},
 journal = {IEEE Trans. Image Process.},
 pages = {1882},
 primaryclass = {cs.CV},
 publisher = {IEEE},
 title = {On Data Augmentation for {GAN} Training},
 volume = {30},
 year = {2021}
}

@misc{transflow,
 archiveprefix = {arXiv},
 author = {Benno Käch and Dirk Krücker and Isabell Melzer-Pellmann},
 eprint = {2211.13623},
 link = {https://arxiv.org/abs/2211.13623},
 primaryclass = {hep-ex},
 title = {Point Cloud Generation using Transformer Encoders and Normalising Flows},
 type = {arXiv},
 year = {2022}
}

@inproceedings{transformers,
 author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 eprint = {1409.3215},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sequence to Sequence Learning with Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf},
 volume = {27},
 year = {2014}
}

@misc{Transgan,
 author = {Käch, Benno},
 title = {{Flow Transformer GAN} Code},
 url = {https://github.com/kaechb/LitJetNet/tree/neurips}
}

@inproceedings{treegan,
 archiveprefix = {arXiv},
 author = {Dong Wook Shu and Sung Woo Park and Junseok Kwon},
 booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
 doi = {10.1109/ICCV.2019.00396},
 eprint = {1905.06292},
 pages = {3858},
 primaryclass = {cs.CV},
 title = {{3D} Point Cloud Generative Adversarial Network Based on Tree Structured Graph Convolutions},
 year = {2019}
}

@article{tsne,
 author = {van der Maaten, Laurens and Hinton, Geoffrey},
 journal = {J. Mach. Learn. Res.},
 note = {\href{http://www.jmlr.org/papers/v9/vandermaaten08a.html}{http://www.jmlr.org/papers/v9/vandermaaten08a.html}},
 pages = {2579},
 title = {Visualizing Data using {t-SNE}},
 volume = {9},
 year = {2008}
}

@inproceedings{TTUR,
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 booktitle = {Advances in Neural Information Processing Systems},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1706.08500},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 eprint = {1706.08500},
 keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 pages = {6626},
 publisher = {Curran Associates, Inc.},
 title = {{GANs} Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
 url = {http://papers.nips.cc/paper/7240-gans-trained-by-a-two-time-scale-update-rule-converge-to-a-local-nash-equilibrium.pdf},
 volume = {30},
 year = {2017}
}

@misc{unet,
 archiveprefix = {arXiv},
 author = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
 eprint = {1505.04597},
 link = {https://arxiv.org/abs/1505.04597},
 primaryclass = {cs.CV},
 title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
 type = {arXiv},
 year = {2015}
}

@article{universal,
 abstract = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
 author = {Cybenko, G.},
 bdsk-url-1 = {https://doi.org/10.1007/BF02551274},
 date = {1989-12-01},
 date-added = {2023-11-28 09:17:30 +0100},
 date-modified = {2023-11-28 09:17:30 +0100},
 doi = {10.1007/BF02551274},
 id = {Cybenko1989},
 journal = {Math. Control Signals Syst.},
 number = {4},
 pages = {303--314},
 title = {{Approximation by superpositions of a sigmoidal function}},
 url = {https://doi.org/10.1007/BF02551274},
 volume = {2},
 year = {1989}
}

@misc{vae,
 archiveprefix = {arXiv},
 author = {Diederik P Kingma and Max Welling},
 eprint = {1312.6114},
 link = {https://arxiv.org/abs/1312.6114},
 primaryclass = {stat.ML},
 title = {Auto-Encoding Variational Bayes},
 type = {arXiv},
 year = {2013}
}

@misc{vaeblurry,
 author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1702.08658},
 keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Towards Deeper Understanding of Variational Autoencoding Models},
 url = {https://arxiv.org/abs/1702.08658},
 year = {2017}
}

@article{vaetutorial,
 archiveprefix = {arXiv},
 author = {Kingma, Diederik P. and Welling, Max},
 doi = {10.1561/2200000056},
 eprint = {1906.02691},
 issn = {1935-8245},
 journal = {Found. Trends~Mach. Learn.},
 number = {4},
 pages = {307--392},
 primaryclass = {cs.LG},
 publisher = {Now Publishers},
 title = {{An Introduction to Variational Autoencoders}},
 url = {http://dx.doi.org/10.1561/2200000056},
 volume = {12},
 year = {2019}
}

@inproceedings{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
 booktitle = {Advances in neural information processing systems},
 pages = {5998--6008},
 title = {Attention is all you need},
 year = {2017}
}

@misc{videogan,
 author = {Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1609.02612},
 keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
 publisher = {arXiv},
 title = {Generating Videos with Scene Dynamics},
 url = {https://arxiv.org/abs/1609.02612},
 year = {2016}
}

@unpublished{wang2020rethinking,
 author = {Wang, He and Jiang, Zetian and Yi, Li and Mo, Kaichun and Su, Hao and Guibas, Leonidas J},
 eprint = {2006.07029},
 primaryclass = {cs.CV},
 title = {Rethinking sampling in {3D} point cloud generative adversarial networks},
 year = {2020}
}

@article{weakfermi,
 abstract = {Eine quantitative Theorie des β-Zerfalls wird vorgeschlagen, in welcher man die Existenz des Neutrinos annimmt, und die Emission der Elektronen und Neutrinos aus einem Kern beim β-Zerfall mit einer {\"a}hnlichen Methode behandelt, wie die Emission eines Lichtquants aus einem angeregten Atom in der Strahlungstheorie. Formeln f{\"u}r die Lebensdauer und f{\"u}r die Form des emittierten kontinuierlichen β- Strahlenspektrums werden abgeleitet und mit der Erfahrung verglichen.},
 author = {Fermi, E.},
 bdsk-url-1 = {https://doi.org/10.1007/BF01351864},
 date = {1934/03/01},
 date-added = {2024-02-08 08:05:56 +0100},
 date-modified = {2024-02-08 08:05:56 +0100},
 doi = {10.1007/BF01351864},
 id = {Fermi1934},
 isbn = {0044-3328},
 journal = {Z. Phys.},
 number = {3},
 pages = {161--177},
 reportnumber = {UCRL-TRANS-726},
 title = {{An attempt of a theory of beta radiation. 1.}},
 url = {https://doi.org/10.1007/BF01351864},
 volume = {88},
 year = {1934}
}

@misc{weightnorm,
 archiveprefix = {arXiv},
 author = {Tim Salimans and Diederik P. Kingma},
 eprint = {1602.07868},
 link = {https://arxiv.org/abs/1602.07868},
 primaryclass = {cs.LG},
 title = {Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},
 type = {arXiv},
 year = {2016}
}

@misc{weightnormgan,
 archiveprefix = {arXiv},
 author = {Sitao Xiang and Hao Li},
 eprint = {1704.03971},
 link = {https://arxiv.org/abs/1704.03971},
 primaryclass = {stat.ML},
 title = {On the Effects of Batch and Weight Normalization in Generative Adversarial Networks},
 type = {arXiv},
 year = {2017}
}

@unpublished{WGAN,
 archiveprefix = {arXiv},
 author = {Martin Arjovsky and Soumith Chintala and L{\'{e}}on Bottou},
 eprint = {1701.07875},
 link = {https://arxiv.org/abs/1701.07875},
 primaryclass = {stat.ML},
 title = {Wasserstein {GAN}},
 type = {arXiv},
 year = {2017}
}

@inproceedings{wgangp,
 archiveprefix = {arXiv},
 author = {Ishaan Gulrajani and Faruk Ahmed and Martin Arjovsky and Vincent Dumoulin and Aaron Courville},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 eprint = {1704.00028},
 link = {https://arxiv.org/abs/1704.00028},
 pages = {5767},
 primaryclass = {cs.LG},
 publisher = {Curran Associates, Inc.},
 title = {Improved Training of {Wasserstein} {GANs}},
 type = {arXiv},
 url = {http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.pdf},
 volume = {30},
 year = {2017}
}

@misc{widresnets,
 archiveprefix = {arXiv},
 author = {Sergey Zagoruyko and Nikos Komodakis},
 eprint = {1605.07146},
 link = {https://arxiv.org/abs/1605.07146},
 primaryclass = {cs.CV},
 title = {Wide Residual Networks},
 type = {arXiv},
 year = {2017}
}

@article{xiong2021nystromformer,
 author = {Xiong, Yunyang and Zeng, Zhanpeng and Chakraborty, Rudrasis and Tan, Mingxing and Fung, Glenn and Li, Yin and Singh, Vikas},
 booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
 title = {Nystr{\"o}mformer: A Nystr{\"o}m-based Algorithm for Approximating Self-Attention},
 year = {2021}
}

@unpublished{zhao_2020,
 archiveprefix = {arXiv},
 author = {Zhengli Zhao and Zizhao Zhang and Ting Chen and Sameer Singh and Han Zhang},
 eprint = {2006.02595},
 link = {https://arxiv.org/abs/2006.02595},
 primaryclass = {cs.LG},
 title = {Image Augmentations for {GAN} Training},
 type = {arXiv},
 year = {2020}
}

@article{Zwicky:1937zza,
 author = {Zwicky, F.},
 doi = {10.1086/143864},
 journal = {Astrophys. J.},
 pages = {217--246},
 title = {{On the Masses of Nebulae and of Clusters of Nebulae}},
 volume = {86},
 year = {1937}
}
